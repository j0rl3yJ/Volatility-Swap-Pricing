{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Volatility_Swap Pricing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXw73PMq6wrW"
      },
      "source": [
        "# PRICING THE VOLATILITY SWAP USING CONSTANT BLACK & SCHOLES MODEL UNDER CONSTANT VOLATILITY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpUYSHMti4zA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13b64b9-7260-43d5-d070-b77dd352027e"
      },
      "source": [
        "!pip install sobol-seq\n",
        "!pip install tbb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sobol-seq\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/df/6c4ad25c0b48545a537b631030f7de7e4abb939e6d2964ac2169d4379c85/sobol_seq-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sobol-seq) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sobol-seq) (1.19.5)\n",
            "Installing collected packages: sobol-seq\n",
            "Successfully installed sobol-seq-0.2.0\n",
            "Collecting tbb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/d2/405b466a345dddba90db0f0241fbaf0580665a82bad5a712aee31a0d7d94/tbb-2021.3.0-py2.py3-none-manylinux1_x86_64.whl (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: tbb\n",
            "Successfully installed tbb-2021.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1pk8p8V2UjK"
      },
      "source": [
        "IMPORT RELEVANT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sFd1nHm2Ir0"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "from time import time\n",
        "import sobol_seq\n",
        "import scipy.stats as si\n",
        "import sympy as sy\n",
        "from sympy.stats import Normal, cdf\n",
        "from sympy import init_printing\n",
        "import random\n",
        "\n",
        "#Visualizing Libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "#Split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Normalize the dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Create the model\n",
        "from keras import Input\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#Evaluate the model\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
        "\n",
        "#Multithreading\n",
        "from numba import jit,njit, config, threading_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrG2DiD-jGIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d1d0be-51c4-48d1-ed5f-2e7097eed221"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIcEIgYz24-1"
      },
      "source": [
        "INPUT PARAMETERS FOR CALL & PUT OPTION, VARIANCE AND VOLATILITY SWAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EForBxrn2qbT"
      },
      "source": [
        "#Input Parameters:\n",
        "# S: spot price\n",
        "# K_array: array of strike prices\n",
        "# T: time to maturity\n",
        "# r: Risk free interest rate\n",
        "# sigma_array: array of volatilities of underlying asset\n",
        "# n: number of strike prices for approximation\n",
        "S = 1020#float(input(\"Spot Price = \"))\n",
        "r = 0.04#float(input(\"Risk free interest rate in decimal = \"))\n",
        "T = 0.25#float(input(\"Time in months = \"))/12\n",
        "n = 9#int(input(\"How many strike prices do you want to enter? :\"))\n",
        "SD_avg_variance = 0.01\n",
        "K_array = np.array([800,850,900,950,1000,1050,1100,1150,1200])\n",
        "#vol_array = np.array([0.29,0.28,0.27,0.26,0.25,0.24,0.23,0.22,0.21])\n",
        "SD_avg_variance = 0.01\n",
        "principal = 100#million dollars\n",
        "paid_vol = 0.23#paid volatility"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ojcXgs23GlP"
      },
      "source": [
        "CALCULATE F0:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-iz3qnT2-J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42791589-d856-4501-9315-2d0432c72a34"
      },
      "source": [
        "F0 = S * np.exp(r*T)\n",
        "print(\"F0=\",F0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F0= 1030.2511704258513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcsZia-Z3QFc"
      },
      "source": [
        "CALCULATE S*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HIDOiB23NDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8fee15-eae8-4278-fdc6-40c24ad31ae0"
      },
      "source": [
        "S_star = 0\n",
        "for i in range(n):\n",
        "    if(K_array[i]<F0):\n",
        "        S_star = K_array[i]\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(S_star)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "halUz4Et3XUM"
      },
      "source": [
        "def euro_vanilla_call(S, K_call, T, r, vol_call):\n",
        "   \n",
        "    d1 = (np.log(S / K_call) + (r + 0.5 * vol_call ** 2) * T) / (vol_call * np.sqrt(T))\n",
        "    d2 = (np.log(S / K_call) + (r - 0.5 * vol_call ** 2) * T) / (vol_call * np.sqrt(T))\n",
        "\n",
        "    call = (S * si.norm.cdf(d1, 0.0, 1.0) - K_call * np.exp(-r * T) * si.norm.cdf(d2, 0.0, 1.0))\n",
        "\n",
        "    return call"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMR2Cyxa3c7m"
      },
      "source": [
        "def euro_vanilla_put(S,K_put,T,r,vol_put):\n",
        "    \n",
        "    d1 = (np.log(S / K_put) + (r + 0.5 * vol_put ** 2) * T) / (vol_put * np.sqrt(T))\n",
        "    d2 = (np.log(S / K_put) + (r - 0.5 * vol_put ** 2) * T) / (vol_put * np.sqrt(T))\n",
        "\n",
        "    put = ((K_put*np.exp(-r*T)* si.norm.cdf(-d2,0.0,1.0)) - (S * si.norm.cdf(-d1, 0.0, 1.0)))\n",
        "    \n",
        "    return put"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWKms55j3jKn"
      },
      "source": [
        "CALCULATE THE APPROXIMATION FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy3wuD8R3f_Z"
      },
      "source": [
        "def Q(K_Q,vol_Q):\n",
        "    if(K_Q < S_star):\n",
        "        return euro_vanilla_put(S,K_Q,T,r,vol_Q)\n",
        "    elif(K_Q > S_star):\n",
        "        return euro_vanilla_call(S,K_Q,T,r,vol_Q)\n",
        "    elif(K_Q == S_star):\n",
        "        return (0.5*(euro_vanilla_call(S,K_Q,T,r,vol_Q) + euro_vanilla_put(S,K_Q,T,r,vol_Q)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX8MMinl3nVt"
      },
      "source": [
        "def approx(n,K,vol):\n",
        "    approxed = 0\n",
        "    for i in range(n):\n",
        "        if(i == 0):\n",
        "            delta_K = K[1] - K[0]\n",
        "        elif(i >= 1 and i <= (n-2)):\n",
        "            delta_K = 0.5*(K[i+1] - K[i-1])\n",
        "        else:\n",
        "            delta_K = K[i] - K[i-1]\n",
        "        approxed += (delta_K/K[i]**2)*np.exp(r*T)*Q(K[i],vol[i])\n",
        "    \n",
        "    return approxed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5OyTVb04E1z"
      },
      "source": [
        "VALUE THE VOLATILITY SWAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVCoD9OH3wTE"
      },
      "source": [
        "def volatility_swap(vol_array):\n",
        "    Expected_variance_price = ((2/T)*np.log(F0/S_star)) - ((2/T)*((F0/S_star)-1)) + ((2/T)*approx(n,K_array,vol_array))\n",
        "    #print(Expected_variance_price)\n",
        "    var_bar = SD_avg_variance**2\n",
        "    Expected_vol_price = np.sqrt(Expected_variance_price) * (1 - ((1/8)*(var_bar/Expected_variance_price**2)))\n",
        "    #print(Expected_vol_price)\n",
        "    swap_price = principal*((Expected_vol_price - paid_vol)*np.exp(-r*T))\n",
        "    #print(swap_price)\n",
        "    #return round(swap_price,2)\n",
        "    return swap_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPZrXj-34bFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea452a8-a6d4-4580-8940-d729b6b78df6"
      },
      "source": [
        "volatility_swap(np.array([0.29,0.28,0.27,0.26,0.25,0.24,0.23,0.22,0.21]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7761940425724816"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB_tlcyo6ZxC"
      },
      "source": [
        "# ANN FOR FAST PREDICTION OF SWAP PRICE FOR DIFFERENT VOLATILITES OF THE UNDERLYING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2QrLpEP7CqZ"
      },
      "source": [
        "CREATE DATASET FOR TRAINING AND TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehHUDl7fJb36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e192007-d062-47ea-9504-f996833133b8"
      },
      "source": [
        "round(random.uniform(50.50, 500.50), 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307.49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnu2wi-5tyJE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "82835435-e42d-4e4e-dc44-bd82dc814a50"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['Sigma1'] = np.random.uniform(0.2,0.6,1000000)\n",
        "df['Sigma2'] = np.random.uniform(0.2,0.6,1000000)\n",
        "df['Sigma3'] = np.random.uniform(0.2,0.6,1000000)\n",
        "df['Sigma4'] = np.random.uniform(0.2,0.6,1000000)\n",
        "df['Sigma5'] = np.random.uniform(0.2,0.6,1000000)\n",
        "df['Sigma6'] = np.random.uniform(0.2,0.6,1000000)\n",
        "df['Sigma7'] = np.random.uniform(0.2,0.6,1000000)\n",
        "df['Sigma8'] = np.random.uniform(0.2,0.6,1000000)\n",
        "df['Sigma9'] = np.random.uniform(0.2,0.6,1000000)\n",
        "\n",
        "#df = round(df,2)\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sigma1</th>\n",
              "      <th>Sigma2</th>\n",
              "      <th>Sigma3</th>\n",
              "      <th>Sigma4</th>\n",
              "      <th>Sigma5</th>\n",
              "      <th>Sigma6</th>\n",
              "      <th>Sigma7</th>\n",
              "      <th>Sigma8</th>\n",
              "      <th>Sigma9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.566112</td>\n",
              "      <td>0.465958</td>\n",
              "      <td>0.206930</td>\n",
              "      <td>0.407574</td>\n",
              "      <td>0.500670</td>\n",
              "      <td>0.564315</td>\n",
              "      <td>0.332249</td>\n",
              "      <td>0.324428</td>\n",
              "      <td>0.564469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.556269</td>\n",
              "      <td>0.506850</td>\n",
              "      <td>0.313259</td>\n",
              "      <td>0.452980</td>\n",
              "      <td>0.393666</td>\n",
              "      <td>0.484757</td>\n",
              "      <td>0.345936</td>\n",
              "      <td>0.539861</td>\n",
              "      <td>0.574729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.577217</td>\n",
              "      <td>0.205450</td>\n",
              "      <td>0.522009</td>\n",
              "      <td>0.355574</td>\n",
              "      <td>0.430149</td>\n",
              "      <td>0.565506</td>\n",
              "      <td>0.352227</td>\n",
              "      <td>0.503809</td>\n",
              "      <td>0.395840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.486204</td>\n",
              "      <td>0.263333</td>\n",
              "      <td>0.472796</td>\n",
              "      <td>0.591504</td>\n",
              "      <td>0.298740</td>\n",
              "      <td>0.393468</td>\n",
              "      <td>0.351547</td>\n",
              "      <td>0.346432</td>\n",
              "      <td>0.444187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.558517</td>\n",
              "      <td>0.232624</td>\n",
              "      <td>0.393309</td>\n",
              "      <td>0.254422</td>\n",
              "      <td>0.409031</td>\n",
              "      <td>0.527585</td>\n",
              "      <td>0.408740</td>\n",
              "      <td>0.315202</td>\n",
              "      <td>0.378234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999995</th>\n",
              "      <td>0.319219</td>\n",
              "      <td>0.439904</td>\n",
              "      <td>0.569632</td>\n",
              "      <td>0.350193</td>\n",
              "      <td>0.474548</td>\n",
              "      <td>0.510800</td>\n",
              "      <td>0.583514</td>\n",
              "      <td>0.353221</td>\n",
              "      <td>0.475620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999996</th>\n",
              "      <td>0.404504</td>\n",
              "      <td>0.215001</td>\n",
              "      <td>0.262104</td>\n",
              "      <td>0.226461</td>\n",
              "      <td>0.381425</td>\n",
              "      <td>0.298641</td>\n",
              "      <td>0.496023</td>\n",
              "      <td>0.313943</td>\n",
              "      <td>0.513095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999997</th>\n",
              "      <td>0.501005</td>\n",
              "      <td>0.357932</td>\n",
              "      <td>0.226633</td>\n",
              "      <td>0.275796</td>\n",
              "      <td>0.392505</td>\n",
              "      <td>0.277055</td>\n",
              "      <td>0.427020</td>\n",
              "      <td>0.543148</td>\n",
              "      <td>0.246774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999998</th>\n",
              "      <td>0.414424</td>\n",
              "      <td>0.399121</td>\n",
              "      <td>0.247482</td>\n",
              "      <td>0.366483</td>\n",
              "      <td>0.357625</td>\n",
              "      <td>0.329986</td>\n",
              "      <td>0.270809</td>\n",
              "      <td>0.222088</td>\n",
              "      <td>0.526260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999999</th>\n",
              "      <td>0.303598</td>\n",
              "      <td>0.443491</td>\n",
              "      <td>0.249565</td>\n",
              "      <td>0.316673</td>\n",
              "      <td>0.515157</td>\n",
              "      <td>0.541437</td>\n",
              "      <td>0.456295</td>\n",
              "      <td>0.268424</td>\n",
              "      <td>0.584462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Sigma1    Sigma2    Sigma3  ...    Sigma7    Sigma8    Sigma9\n",
              "0       0.566112  0.465958  0.206930  ...  0.332249  0.324428  0.564469\n",
              "1       0.556269  0.506850  0.313259  ...  0.345936  0.539861  0.574729\n",
              "2       0.577217  0.205450  0.522009  ...  0.352227  0.503809  0.395840\n",
              "3       0.486204  0.263333  0.472796  ...  0.351547  0.346432  0.444187\n",
              "4       0.558517  0.232624  0.393309  ...  0.408740  0.315202  0.378234\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "999995  0.319219  0.439904  0.569632  ...  0.583514  0.353221  0.475620\n",
              "999996  0.404504  0.215001  0.262104  ...  0.496023  0.313943  0.513095\n",
              "999997  0.501005  0.357932  0.226633  ...  0.427020  0.543148  0.246774\n",
              "999998  0.414424  0.399121  0.247482  ...  0.270809  0.222088  0.526260\n",
              "999999  0.303598  0.443491  0.249565  ...  0.456295  0.268424  0.584462\n",
              "\n",
              "[1000000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgnPf2RX18-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ed1416-e342-4b81-b16a-23bb5258b425"
      },
      "source": [
        "%%time\n",
        "df['Swap Price'] = [volatility_swap(np.array(df.loc[x,:].values)) for x in range(1000000)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39min 1s, sys: 2min 21s, total: 41min 23s\n",
            "Wall time: 38min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DHknAcQyd0F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ea245cbf-b745-4384-e043-15334d82fac3"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sigma1</th>\n",
              "      <th>Sigma2</th>\n",
              "      <th>Sigma3</th>\n",
              "      <th>Sigma4</th>\n",
              "      <th>Sigma5</th>\n",
              "      <th>Sigma6</th>\n",
              "      <th>Sigma7</th>\n",
              "      <th>Sigma8</th>\n",
              "      <th>Sigma9</th>\n",
              "      <th>Swap Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.315699</td>\n",
              "      <td>0.296761</td>\n",
              "      <td>0.492697</td>\n",
              "      <td>0.380812</td>\n",
              "      <td>0.458356</td>\n",
              "      <td>0.595305</td>\n",
              "      <td>0.550193</td>\n",
              "      <td>0.505010</td>\n",
              "      <td>0.338467</td>\n",
              "      <td>18.239751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.425359</td>\n",
              "      <td>0.333196</td>\n",
              "      <td>0.203899</td>\n",
              "      <td>0.439249</td>\n",
              "      <td>0.547067</td>\n",
              "      <td>0.311228</td>\n",
              "      <td>0.337775</td>\n",
              "      <td>0.580026</td>\n",
              "      <td>0.223251</td>\n",
              "      <td>13.735260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.301369</td>\n",
              "      <td>0.481476</td>\n",
              "      <td>0.598509</td>\n",
              "      <td>0.536923</td>\n",
              "      <td>0.423904</td>\n",
              "      <td>0.449820</td>\n",
              "      <td>0.466943</td>\n",
              "      <td>0.518354</td>\n",
              "      <td>0.564526</td>\n",
              "      <td>21.128184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.532343</td>\n",
              "      <td>0.547209</td>\n",
              "      <td>0.263670</td>\n",
              "      <td>0.505458</td>\n",
              "      <td>0.368612</td>\n",
              "      <td>0.442494</td>\n",
              "      <td>0.323394</td>\n",
              "      <td>0.488251</td>\n",
              "      <td>0.304966</td>\n",
              "      <td>16.530578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.450506</td>\n",
              "      <td>0.453044</td>\n",
              "      <td>0.506189</td>\n",
              "      <td>0.500346</td>\n",
              "      <td>0.284136</td>\n",
              "      <td>0.487196</td>\n",
              "      <td>0.506551</td>\n",
              "      <td>0.515358</td>\n",
              "      <td>0.220384</td>\n",
              "      <td>18.031803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.387541</td>\n",
              "      <td>0.501126</td>\n",
              "      <td>0.343789</td>\n",
              "      <td>0.264203</td>\n",
              "      <td>0.417322</td>\n",
              "      <td>0.307275</td>\n",
              "      <td>0.332555</td>\n",
              "      <td>0.467238</td>\n",
              "      <td>0.286493</td>\n",
              "      <td>12.042590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.458114</td>\n",
              "      <td>0.489728</td>\n",
              "      <td>0.461926</td>\n",
              "      <td>0.318790</td>\n",
              "      <td>0.371646</td>\n",
              "      <td>0.490841</td>\n",
              "      <td>0.595863</td>\n",
              "      <td>0.440407</td>\n",
              "      <td>0.446100</td>\n",
              "      <td>18.354496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.395812</td>\n",
              "      <td>0.407319</td>\n",
              "      <td>0.351811</td>\n",
              "      <td>0.529293</td>\n",
              "      <td>0.314632</td>\n",
              "      <td>0.468473</td>\n",
              "      <td>0.316840</td>\n",
              "      <td>0.211521</td>\n",
              "      <td>0.253720</td>\n",
              "      <td>12.581864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.356289</td>\n",
              "      <td>0.351813</td>\n",
              "      <td>0.500286</td>\n",
              "      <td>0.504051</td>\n",
              "      <td>0.558816</td>\n",
              "      <td>0.399909</td>\n",
              "      <td>0.585904</td>\n",
              "      <td>0.334587</td>\n",
              "      <td>0.348231</td>\n",
              "      <td>18.421847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.580080</td>\n",
              "      <td>0.447754</td>\n",
              "      <td>0.243524</td>\n",
              "      <td>0.536369</td>\n",
              "      <td>0.207917</td>\n",
              "      <td>0.355799</td>\n",
              "      <td>0.372215</td>\n",
              "      <td>0.354239</td>\n",
              "      <td>0.229864</td>\n",
              "      <td>12.794040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sigma1    Sigma2    Sigma3  ...    Sigma8    Sigma9  Swap Price\n",
              "0     0.315699  0.296761  0.492697  ...  0.505010  0.338467   18.239751\n",
              "1     0.425359  0.333196  0.203899  ...  0.580026  0.223251   13.735260\n",
              "2     0.301369  0.481476  0.598509  ...  0.518354  0.564526   21.128184\n",
              "3     0.532343  0.547209  0.263670  ...  0.488251  0.304966   16.530578\n",
              "4     0.450506  0.453044  0.506189  ...  0.515358  0.220384   18.031803\n",
              "...        ...       ...       ...  ...       ...       ...         ...\n",
              "9995  0.387541  0.501126  0.343789  ...  0.467238  0.286493   12.042590\n",
              "9996  0.458114  0.489728  0.461926  ...  0.440407  0.446100   18.354496\n",
              "9997  0.395812  0.407319  0.351811  ...  0.211521  0.253720   12.581864\n",
              "9998  0.356289  0.351813  0.500286  ...  0.334587  0.348231   18.421847\n",
              "9999  0.580080  0.447754  0.243524  ...  0.354239  0.229864   12.794040\n",
              "\n",
              "[10000 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW0gS32P6nrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "a1871462-40c9-4487-fbce-d959fe765b68"
      },
      "source": [
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.31569929, 0.29676074, 0.49269742, ..., 0.55019293, 0.50501011,\n",
              "        0.33846684],\n",
              "       [0.42535858, 0.33319566, 0.20389937, ..., 0.3377751 , 0.5800262 ,\n",
              "        0.22325069],\n",
              "       [0.30136929, 0.48147551, 0.59850869, ..., 0.46694342, 0.51835428,\n",
              "        0.56452558],\n",
              "       ...,\n",
              "       [0.39581231, 0.40731934, 0.35181066, ..., 0.31684006, 0.21152115,\n",
              "        0.2537203 ],\n",
              "       [0.35628869, 0.35181299, 0.50028613, ..., 0.58590366, 0.33458668,\n",
              "        0.34823096],\n",
              "       [0.58007978, 0.44775359, 0.24352365, ..., 0.37221504, 0.35423883,\n",
              "        0.22986405]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLBaOMtH_cmP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0013b482-7eea-4532-97b0-4edc23c3dcfa"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDgKvnTmETeV"
      },
      "source": [
        "SPLIT THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wl-OmPnD-HL"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVz4NmqtEc8l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cf65d05-36ef-4a73-d677-53c6a5a45d57"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6knoLKbIEtHz"
      },
      "source": [
        "NORMALIZE THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3DRoPbdEgp6"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr05_YqpKN8Q"
      },
      "source": [
        "CREATE THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1WAtlUfE0zt"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtZ_lNDKWhR"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(9,activation='elu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(9,activation='elu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(9,activation='elu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(9,activation='elu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuUb6aNAKZp-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ce1e132-f63c-4857-e90a-2f468bb4ee83"
      },
      "source": [
        "%%time\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit(x=X_train, y=y_train, epochs=1000,\n",
        "            validation_data=(X_test, y_test),batch_size = 128, \n",
        "            verbose=1, callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 197.3303 - val_loss: 151.7973\n",
            "Epoch 2/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 100.6612 - val_loss: 31.0812\n",
            "Epoch 3/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 35.9325 - val_loss: 6.1854\n",
            "Epoch 4/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 31.1147 - val_loss: 6.6468\n",
            "Epoch 5/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 28.6708 - val_loss: 6.4146\n",
            "Epoch 6/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 26.1647 - val_loss: 6.3388\n",
            "Epoch 7/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 24.3280 - val_loss: 5.9252\n",
            "Epoch 8/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 23.2901 - val_loss: 5.7565\n",
            "Epoch 9/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 22.3782 - val_loss: 5.7656\n",
            "Epoch 10/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 21.4751 - val_loss: 5.6868\n",
            "Epoch 11/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 20.2276 - val_loss: 5.7711\n",
            "Epoch 12/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 19.9931 - val_loss: 5.3436\n",
            "Epoch 13/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 18.7217 - val_loss: 5.3203\n",
            "Epoch 14/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 18.4174 - val_loss: 5.5354\n",
            "Epoch 15/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 18.1931 - val_loss: 5.2138\n",
            "Epoch 16/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 17.7401 - val_loss: 5.0591\n",
            "Epoch 17/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 16.7998 - val_loss: 4.7383\n",
            "Epoch 18/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 16.8031 - val_loss: 4.5641\n",
            "Epoch 19/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 16.1784 - val_loss: 4.3119\n",
            "Epoch 20/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 15.5653 - val_loss: 3.8762\n",
            "Epoch 21/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 15.1804 - val_loss: 3.5749\n",
            "Epoch 22/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 15.0928 - val_loss: 3.0728\n",
            "Epoch 23/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 13.8392 - val_loss: 2.5560\n",
            "Epoch 24/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 14.0409 - val_loss: 2.4099\n",
            "Epoch 25/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 13.2371 - val_loss: 2.0527\n",
            "Epoch 26/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 13.0500 - val_loss: 1.9741\n",
            "Epoch 27/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 12.6617 - val_loss: 1.5293\n",
            "Epoch 28/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 12.5551 - val_loss: 1.7103\n",
            "Epoch 29/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 12.3685 - val_loss: 1.3837\n",
            "Epoch 30/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 11.5502 - val_loss: 1.2422\n",
            "Epoch 31/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 11.4811 - val_loss: 1.3335\n",
            "Epoch 32/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 11.5345 - val_loss: 1.1141\n",
            "Epoch 33/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 11.4575 - val_loss: 1.1822\n",
            "Epoch 34/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 10.8486 - val_loss: 1.2683\n",
            "Epoch 35/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 10.9578 - val_loss: 1.1540\n",
            "Epoch 36/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 10.4943 - val_loss: 1.0300\n",
            "Epoch 37/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 10.5462 - val_loss: 0.9130\n",
            "Epoch 38/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 10.1971 - val_loss: 0.8783\n",
            "Epoch 39/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.9468 - val_loss: 1.1494\n",
            "Epoch 40/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.7794 - val_loss: 1.0657\n",
            "Epoch 41/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.8213 - val_loss: 0.9581\n",
            "Epoch 42/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.3182 - val_loss: 0.7463\n",
            "Epoch 43/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.3256 - val_loss: 0.6342\n",
            "Epoch 44/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.2404 - val_loss: 0.7308\n",
            "Epoch 45/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 9.0008 - val_loss: 0.6137\n",
            "Epoch 46/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.9232 - val_loss: 0.6393\n",
            "Epoch 47/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.5372 - val_loss: 0.7031\n",
            "Epoch 48/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.6893 - val_loss: 0.5833\n",
            "Epoch 49/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.7287 - val_loss: 0.6653\n",
            "Epoch 50/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.4215 - val_loss: 0.5417\n",
            "Epoch 51/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.1695 - val_loss: 0.9038\n",
            "Epoch 52/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.8222 - val_loss: 0.6503\n",
            "Epoch 53/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.1634 - val_loss: 0.4038\n",
            "Epoch 54/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.0199 - val_loss: 0.4679\n",
            "Epoch 55/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 8.2207 - val_loss: 0.7454\n",
            "Epoch 56/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.9551 - val_loss: 0.6381\n",
            "Epoch 57/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.7556 - val_loss: 0.5883\n",
            "Epoch 58/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.9602 - val_loss: 0.4042\n",
            "Epoch 59/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.6054 - val_loss: 0.5893\n",
            "Epoch 60/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.7794 - val_loss: 0.7432\n",
            "Epoch 61/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.4159 - val_loss: 0.7088\n",
            "Epoch 62/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.4920 - val_loss: 0.6456\n",
            "Epoch 63/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.4710 - val_loss: 0.4256\n",
            "Epoch 64/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.3103 - val_loss: 0.4721\n",
            "Epoch 65/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.4298 - val_loss: 0.4134\n",
            "Epoch 66/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.0596 - val_loss: 0.4365\n",
            "Epoch 67/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.0531 - val_loss: 0.5935\n",
            "Epoch 68/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.0907 - val_loss: 0.4731\n",
            "Epoch 69/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.9655 - val_loss: 0.6210\n",
            "Epoch 70/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.1114 - val_loss: 0.4156\n",
            "Epoch 71/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 7.2605 - val_loss: 0.3998\n",
            "Epoch 72/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.9630 - val_loss: 0.5292\n",
            "Epoch 73/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.9472 - val_loss: 0.3943\n",
            "Epoch 74/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.6696 - val_loss: 0.3760\n",
            "Epoch 75/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.6650 - val_loss: 0.6786\n",
            "Epoch 76/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.5979 - val_loss: 0.3851\n",
            "Epoch 77/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.6150 - val_loss: 0.4892\n",
            "Epoch 78/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.3827 - val_loss: 0.2756\n",
            "Epoch 79/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.5446 - val_loss: 0.5606\n",
            "Epoch 80/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.7146 - val_loss: 0.3850\n",
            "Epoch 81/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.5091 - val_loss: 0.3523\n",
            "Epoch 82/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.3260 - val_loss: 0.3588\n",
            "Epoch 83/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.5019 - val_loss: 0.4695\n",
            "Epoch 84/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.4666 - val_loss: 0.4681\n",
            "Epoch 85/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.4509 - val_loss: 0.3696\n",
            "Epoch 86/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.1192 - val_loss: 0.3799\n",
            "Epoch 87/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.2640 - val_loss: 0.4525\n",
            "Epoch 88/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.2150 - val_loss: 0.6877\n",
            "Epoch 89/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.9703 - val_loss: 0.4062\n",
            "Epoch 90/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.9750 - val_loss: 0.5189\n",
            "Epoch 91/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.0951 - val_loss: 0.3092\n",
            "Epoch 92/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.0977 - val_loss: 0.3467\n",
            "Epoch 93/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.6506 - val_loss: 0.5019\n",
            "Epoch 94/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.9291 - val_loss: 0.4270\n",
            "Epoch 95/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.7972 - val_loss: 0.4881\n",
            "Epoch 96/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.7589 - val_loss: 0.3968\n",
            "Epoch 97/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 6.0458 - val_loss: 0.2571\n",
            "Epoch 98/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.9674 - val_loss: 0.3695\n",
            "Epoch 99/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.8988 - val_loss: 0.4312\n",
            "Epoch 100/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.4820 - val_loss: 0.3314\n",
            "Epoch 101/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.7037 - val_loss: 0.3601\n",
            "Epoch 102/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.6615 - val_loss: 0.2495\n",
            "Epoch 103/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.4874 - val_loss: 0.2780\n",
            "Epoch 104/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.3977 - val_loss: 0.2619\n",
            "Epoch 105/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.4270 - val_loss: 0.3072\n",
            "Epoch 106/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.4961 - val_loss: 0.4269\n",
            "Epoch 107/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.3719 - val_loss: 0.3285\n",
            "Epoch 108/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.3593 - val_loss: 0.3247\n",
            "Epoch 109/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.2549 - val_loss: 0.3030\n",
            "Epoch 110/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.3040 - val_loss: 0.3568\n",
            "Epoch 111/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.3202 - val_loss: 0.2503\n",
            "Epoch 112/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.1512 - val_loss: 0.2449\n",
            "Epoch 113/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.2353 - val_loss: 0.3010\n",
            "Epoch 114/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.1001 - val_loss: 0.2788\n",
            "Epoch 115/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.2577 - val_loss: 0.2896\n",
            "Epoch 116/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.9788 - val_loss: 0.3777\n",
            "Epoch 117/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.1074 - val_loss: 0.3194\n",
            "Epoch 118/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 5.0950 - val_loss: 0.3150\n",
            "Epoch 119/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.7920 - val_loss: 0.3803\n",
            "Epoch 120/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.9400 - val_loss: 0.3039\n",
            "Epoch 121/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.9314 - val_loss: 0.2730\n",
            "Epoch 122/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.8499 - val_loss: 0.3894\n",
            "Epoch 123/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.7880 - val_loss: 0.2853\n",
            "Epoch 124/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.8416 - val_loss: 0.3963\n",
            "Epoch 125/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.6211 - val_loss: 0.2448\n",
            "Epoch 126/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.7178 - val_loss: 0.2926\n",
            "Epoch 127/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.7337 - val_loss: 0.2894\n",
            "Epoch 128/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.8330 - val_loss: 0.2770\n",
            "Epoch 129/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.7288 - val_loss: 0.3620\n",
            "Epoch 130/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.6064 - val_loss: 0.2466\n",
            "Epoch 131/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.5635 - val_loss: 0.3109\n",
            "Epoch 132/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.4738 - val_loss: 0.2298\n",
            "Epoch 133/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.6478 - val_loss: 0.3206\n",
            "Epoch 134/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.5766 - val_loss: 0.2271\n",
            "Epoch 135/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.4870 - val_loss: 0.3374\n",
            "Epoch 136/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.5062 - val_loss: 0.3708\n",
            "Epoch 137/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.5287 - val_loss: 0.2254\n",
            "Epoch 138/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.3932 - val_loss: 0.3588\n",
            "Epoch 139/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.4469 - val_loss: 0.3337\n",
            "Epoch 140/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.3593 - val_loss: 0.2315\n",
            "Epoch 141/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.2717 - val_loss: 0.2638\n",
            "Epoch 142/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.3175 - val_loss: 0.2777\n",
            "Epoch 143/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.1777 - val_loss: 0.3206\n",
            "Epoch 144/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.1818 - val_loss: 0.2681\n",
            "Epoch 145/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.3326 - val_loss: 0.3111\n",
            "Epoch 146/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 4.0496 - val_loss: 0.3844\n",
            "Epoch 147/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.1250 - val_loss: 0.2769\n",
            "Epoch 148/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.1550 - val_loss: 0.2285\n",
            "Epoch 149/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.9681 - val_loss: 0.4335\n",
            "Epoch 150/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.0806 - val_loss: 0.4388\n",
            "Epoch 151/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.0716 - val_loss: 0.3103\n",
            "Epoch 152/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.0515 - val_loss: 0.2851\n",
            "Epoch 153/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.0185 - val_loss: 0.4057\n",
            "Epoch 154/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 4.0041 - val_loss: 0.3024\n",
            "Epoch 155/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.9548 - val_loss: 0.2379\n",
            "Epoch 156/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.9035 - val_loss: 0.3543\n",
            "Epoch 157/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.8024 - val_loss: 0.1963\n",
            "Epoch 158/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.8982 - val_loss: 0.3483\n",
            "Epoch 159/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.8161 - val_loss: 0.2721\n",
            "Epoch 160/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.7627 - val_loss: 0.2143\n",
            "Epoch 161/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.7150 - val_loss: 0.3174\n",
            "Epoch 162/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.9008 - val_loss: 0.3383\n",
            "Epoch 163/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.6901 - val_loss: 0.2500\n",
            "Epoch 164/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.7985 - val_loss: 0.1990\n",
            "Epoch 165/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.8426 - val_loss: 0.4071\n",
            "Epoch 166/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.7023 - val_loss: 0.4326\n",
            "Epoch 167/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.6919 - val_loss: 0.3063\n",
            "Epoch 168/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.5880 - val_loss: 0.3338\n",
            "Epoch 169/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.6529 - val_loss: 0.3993\n",
            "Epoch 170/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.5338 - val_loss: 0.3305\n",
            "Epoch 171/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.5681 - val_loss: 0.3048\n",
            "Epoch 172/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.5881 - val_loss: 0.2775\n",
            "Epoch 173/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.4648 - val_loss: 0.2513\n",
            "Epoch 174/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.4769 - val_loss: 0.2457\n",
            "Epoch 175/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.5311 - val_loss: 0.2963\n",
            "Epoch 176/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.3668 - val_loss: 0.2545\n",
            "Epoch 177/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.4626 - val_loss: 0.2776\n",
            "Epoch 178/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.3921 - val_loss: 0.3274\n",
            "Epoch 179/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.2857 - val_loss: 0.2968\n",
            "Epoch 180/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.4026 - val_loss: 0.2289\n",
            "Epoch 181/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.3478 - val_loss: 0.1941\n",
            "Epoch 182/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.3629 - val_loss: 0.2583\n",
            "Epoch 183/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.2302 - val_loss: 0.2913\n",
            "Epoch 184/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.3640 - val_loss: 0.3140\n",
            "Epoch 185/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.3655 - val_loss: 0.3363\n",
            "Epoch 186/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1885 - val_loss: 0.2319\n",
            "Epoch 187/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1718 - val_loss: 0.3020\n",
            "Epoch 188/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1794 - val_loss: 0.2411\n",
            "Epoch 189/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1712 - val_loss: 0.2894\n",
            "Epoch 190/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1327 - val_loss: 0.2991\n",
            "Epoch 191/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1558 - val_loss: 0.2677\n",
            "Epoch 192/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.0792 - val_loss: 0.2783\n",
            "Epoch 193/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1333 - val_loss: 0.3554\n",
            "Epoch 194/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 2.9948 - val_loss: 0.2791\n",
            "Epoch 195/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1202 - val_loss: 0.3412\n",
            "Epoch 196/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1162 - val_loss: 0.2261\n",
            "Epoch 197/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.1060 - val_loss: 0.3200\n",
            "Epoch 198/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.0300 - val_loss: 0.3414\n",
            "Epoch 199/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 2.9808 - val_loss: 0.2095\n",
            "Epoch 200/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 2.9996 - val_loss: 0.2371\n",
            "Epoch 201/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 2.9229 - val_loss: 0.2489\n",
            "Epoch 202/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 2.9286 - val_loss: 0.2680\n",
            "Epoch 203/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 2.8367 - val_loss: 0.3976\n",
            "Epoch 204/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 3.0410 - val_loss: 0.1953\n",
            "Epoch 205/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 2.8672 - val_loss: 0.3142\n",
            "Epoch 206/1000\n",
            "55/55 [==============================] - 0s 4ms/step - loss: 2.8692 - val_loss: 0.2175\n",
            "Epoch 00206: early stopping\n",
            "CPU times: user 54.2 s, sys: 6.16 s, total: 1min\n",
            "Wall time: 48.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVUAb_p9Ko4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "3442107a-ce8a-4615-a3c9-112069329413"
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "model_loss.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b1006f278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLQH9u3cMBLM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "58821fe1-e9aa-4bd7-bf20-e357e660e6cd"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.81033467, 18.71489648,  9.99736173, ..., 12.13598207,\n",
              "       13.39542586, 19.23552297])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B-Ui2EkK3qw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bd6d715e-0bef-4c25-c40c-9128b8e00318"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15.975969],\n",
              "       [18.621649],\n",
              "       [10.691629],\n",
              "       ...,\n",
              "       [12.463562],\n",
              "       [13.073429],\n",
              "       [18.821327]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKnxVBmCLUpY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1707032c-9a31-4b46-e3ff-5c280adb1d77"
      },
      "source": [
        "np.sqrt(mean_squared_error(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46633298390852657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCcBVbXmLZah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6ab3e67-ab13-46b3-ea7f-dd8ef4867afe"
      },
      "source": [
        "explained_variance_score(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9762129512287232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kv8CodTLePa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "78a9bc96-8872-417f-f583-e43ba158f50b"
      },
      "source": [
        "result_df = pd.DataFrame()\n",
        "result_df['True values'] = y_test\n",
        "result_df['Predictions'] = predictions\n",
        "result_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True values</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.810335</td>\n",
              "      <td>15.975969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18.714896</td>\n",
              "      <td>18.621649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.997362</td>\n",
              "      <td>10.691629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.636960</td>\n",
              "      <td>17.266794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.433450</td>\n",
              "      <td>15.575157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>14.035750</td>\n",
              "      <td>13.697926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>12.230762</td>\n",
              "      <td>12.391105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>12.135982</td>\n",
              "      <td>12.463562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>13.395426</td>\n",
              "      <td>13.073429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>19.235523</td>\n",
              "      <td>18.821327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      True values  Predictions\n",
              "0       15.810335    15.975969\n",
              "1       18.714896    18.621649\n",
              "2        9.997362    10.691629\n",
              "3       17.636960    17.266794\n",
              "4       15.433450    15.575157\n",
              "...           ...          ...\n",
              "2995    14.035750    13.697926\n",
              "2996    12.230762    12.391105\n",
              "2997    12.135982    12.463562\n",
              "2998    13.395426    13.073429\n",
              "2999    19.235523    18.821327\n",
              "\n",
              "[3000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ8W3NssbIsc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "003fe302-7442-4a05-f78b-3237fb7712ff"
      },
      "source": [
        "sns.scatterplot(x = result_df['True values'], y = result_df['Predictions'], hue = \"Predictions\", data = result_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0ac1c5e240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPb42JFnLZ0G"
      },
      "source": [
        "# ANN USING TWIN NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNGo4Xs-hrCx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "6519f077-5546-461a-ecf2-5e89f4c72526"
      },
      "source": [
        "input_tensor = Input(shape=(None,9))\n",
        "l1 = layers.Dense(9,activation='softplus')(input_tensor)\n",
        "tf.keras.layers.Dropout(rate=0.2)\n",
        "l2 = layers.Dense(9, activation='softplus')(l1)\n",
        "tf.keras.layers.Dropout(rate=0.2)\n",
        "l3 = layers.Dense(9,activation='softplus')(l2)\n",
        "tf.keras.layers.Dropout(rate=0.2)\n",
        "l4 = layers.Dense(9,activation='softplus')(l3)\n",
        "tf.keras.layers.Dropout(rate=0.2)\n",
        "output = layers.Dense(1)(l4)\n",
        "l5 = layers.Dense(9,activation='sigmoid')(output)\n",
        "tf.keras.layers.Dropout(rate=0.2)\n",
        "l6 = layers.Dense(9,activation='sigmoid')(l3)\n",
        "tf.keras.layers.Dropout(rate=0.2)\n",
        "l7 = layers.Dense(9,activation='sigmoid')(l3)\n",
        "tf.keras.layers.Dropout(rate=0.2)\n",
        "l8 = layers.Dense(9,activation='sigmoid')(l3)\n",
        "tf.keras.layers.Dropout(rate=0.2)\n",
        "output_tensor = layers.Dense(9)(l8)\n",
        "\n",
        "model_TN = Model(input_tensor,[output,output_tensor])\n",
        "\n",
        "model_TN.summary()\n",
        "\n",
        "model_TN.compile(optimizer='adam',loss='mse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 9)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, None, 9)      90          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, None, 9)      90          dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, None, 9)      90          dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, None, 9)      90          dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, None, 9)      90          dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, None, 1)      10          dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, None, 9)      90          dense_13[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 550\n",
            "Trainable params: 550\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y-OILBsLlok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e97aaf43-cb45-4add-9591-ebe2f45d73cd"
      },
      "source": [
        "%%time\n",
        "model_TN.fit(x=X_train, y=y_train, epochs=2000,\n",
        "          validation_data=(X_test, y_test),batch_size = 128, \n",
        "          verbose=1, callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 9) for input Tensor(\"input_1:0\", shape=(None, None, 9), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 9) for input Tensor(\"input_1:0\", shape=(None, None, 9), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n",
            "45/55 [=======================>......] - ETA: 0s - loss: 415.5258 - dense_9_loss: 195.9660 - dense_14_loss: 219.5597WARNING:tensorflow:Model was constructed with shape (None, None, 9) for input Tensor(\"input_1:0\", shape=(None, None, 9), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 408.2701 - dense_9_loss: 189.8652 - dense_14_loss: 218.4049 - val_loss: 368.0501 - val_dense_9_loss: 154.9221 - val_dense_14_loss: 213.1280\n",
            "Epoch 2/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 302.7183 - dense_9_loss: 98.9719 - dense_14_loss: 203.7464 - val_loss: 226.7685 - val_dense_9_loss: 29.9944 - val_dense_14_loss: 196.7741\n",
            "Epoch 3/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 196.4344 - dense_9_loss: 8.7940 - dense_14_loss: 187.6405 - val_loss: 187.9365 - val_dense_9_loss: 5.9193 - val_dense_14_loss: 182.0173\n",
            "Epoch 4/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 178.5280 - dense_9_loss: 5.4275 - dense_14_loss: 173.1005 - val_loss: 171.7700 - val_dense_9_loss: 5.5311 - val_dense_14_loss: 166.2389\n",
            "Epoch 5/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 162.5228 - dense_9_loss: 5.0498 - dense_14_loss: 157.4730 - val_loss: 157.0544 - val_dense_9_loss: 5.1299 - val_dense_14_loss: 151.9245\n",
            "Epoch 6/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 149.1483 - dense_9_loss: 4.6609 - dense_14_loss: 144.4874 - val_loss: 144.6006 - val_dense_9_loss: 4.7174 - val_dense_14_loss: 139.8832\n",
            "Epoch 7/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 137.3835 - dense_9_loss: 4.2646 - dense_14_loss: 133.1189 - val_loss: 133.3577 - val_dense_9_loss: 4.3197 - val_dense_14_loss: 129.0379\n",
            "Epoch 8/2000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 126.6474 - dense_9_loss: 3.8671 - dense_14_loss: 122.7803 - val_loss: 123.0013 - val_dense_9_loss: 3.8908 - val_dense_14_loss: 119.1106\n",
            "Epoch 9/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 116.7466 - dense_9_loss: 3.4785 - dense_14_loss: 113.2681 - val_loss: 113.4386 - val_dense_9_loss: 3.4921 - val_dense_14_loss: 109.9466\n",
            "Epoch 10/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 107.5712 - dense_9_loss: 3.1017 - dense_14_loss: 104.4695 - val_loss: 104.5630 - val_dense_9_loss: 3.1253 - val_dense_14_loss: 101.4376\n",
            "Epoch 11/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 99.0440 - dense_9_loss: 2.7420 - dense_14_loss: 96.3020 - val_loss: 96.3012 - val_dense_9_loss: 2.7365 - val_dense_14_loss: 93.5647\n",
            "Epoch 12/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 91.1330 - dense_9_loss: 2.3997 - dense_14_loss: 88.7333 - val_loss: 88.6311 - val_dense_9_loss: 2.4103 - val_dense_14_loss: 86.2208\n",
            "Epoch 13/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 83.7800 - dense_9_loss: 2.0780 - dense_14_loss: 81.7020 - val_loss: 81.4814 - val_dense_9_loss: 2.0653 - val_dense_14_loss: 79.4160\n",
            "Epoch 14/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 76.9634 - dense_9_loss: 1.7825 - dense_14_loss: 75.1808 - val_loss: 74.8832 - val_dense_9_loss: 1.7676 - val_dense_14_loss: 73.1155\n",
            "Epoch 15/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 70.6495 - dense_9_loss: 1.5133 - dense_14_loss: 69.1361 - val_loss: 68.7702 - val_dense_9_loss: 1.4948 - val_dense_14_loss: 67.2754\n",
            "Epoch 16/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 64.8019 - dense_9_loss: 1.2633 - dense_14_loss: 63.5386 - val_loss: 63.1127 - val_dense_9_loss: 1.2474 - val_dense_14_loss: 61.8653\n",
            "Epoch 17/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 59.3984 - dense_9_loss: 1.0404 - dense_14_loss: 58.3580 - val_loss: 57.8980 - val_dense_9_loss: 1.0269 - val_dense_14_loss: 56.8711\n",
            "Epoch 18/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 54.4262 - dense_9_loss: 0.8475 - dense_14_loss: 53.5786 - val_loss: 53.0800 - val_dense_9_loss: 0.8416 - val_dense_14_loss: 52.2384\n",
            "Epoch 19/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 49.8558 - dense_9_loss: 0.6861 - dense_14_loss: 49.1697 - val_loss: 48.6737 - val_dense_9_loss: 0.6950 - val_dense_14_loss: 47.9787\n",
            "Epoch 20/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 45.6611 - dense_9_loss: 0.5513 - dense_14_loss: 45.1098 - val_loss: 44.6321 - val_dense_9_loss: 0.5555 - val_dense_14_loss: 44.0766\n",
            "Epoch 21/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 41.8259 - dense_9_loss: 0.4447 - dense_14_loss: 41.3812 - val_loss: 40.9432 - val_dense_9_loss: 0.4528 - val_dense_14_loss: 40.4904\n",
            "Epoch 22/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 38.3268 - dense_9_loss: 0.3604 - dense_14_loss: 37.9664 - val_loss: 37.5659 - val_dense_9_loss: 0.3766 - val_dense_14_loss: 37.1894\n",
            "Epoch 23/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 35.1338 - dense_9_loss: 0.2984 - dense_14_loss: 34.8354 - val_loss: 34.5074 - val_dense_9_loss: 0.3171 - val_dense_14_loss: 34.1902\n",
            "Epoch 24/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 32.2391 - dense_9_loss: 0.2538 - dense_14_loss: 31.9853 - val_loss: 31.7119 - val_dense_9_loss: 0.2770 - val_dense_14_loss: 31.4349\n",
            "Epoch 25/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 29.6074 - dense_9_loss: 0.2225 - dense_14_loss: 29.3849 - val_loss: 29.1884 - val_dense_9_loss: 0.2470 - val_dense_14_loss: 28.9415\n",
            "Epoch 26/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 27.2266 - dense_9_loss: 0.2003 - dense_14_loss: 27.0262 - val_loss: 26.8996 - val_dense_9_loss: 0.2242 - val_dense_14_loss: 26.6753\n",
            "Epoch 27/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 25.0733 - dense_9_loss: 0.1859 - dense_14_loss: 24.8874 - val_loss: 24.8383 - val_dense_9_loss: 0.2097 - val_dense_14_loss: 24.6287\n",
            "Epoch 28/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 23.1336 - dense_9_loss: 0.1765 - dense_14_loss: 22.9571 - val_loss: 22.9697 - val_dense_9_loss: 0.1997 - val_dense_14_loss: 22.7700\n",
            "Epoch 29/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 21.3858 - dense_9_loss: 0.1694 - dense_14_loss: 21.2163 - val_loss: 21.2966 - val_dense_9_loss: 0.1923 - val_dense_14_loss: 21.1043\n",
            "Epoch 30/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 19.8163 - dense_9_loss: 0.1645 - dense_14_loss: 19.6518 - val_loss: 19.7994 - val_dense_9_loss: 0.1880 - val_dense_14_loss: 19.6115\n",
            "Epoch 31/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 18.4149 - dense_9_loss: 0.1614 - dense_14_loss: 18.2536 - val_loss: 18.4505 - val_dense_9_loss: 0.1830 - val_dense_14_loss: 18.2675\n",
            "Epoch 32/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 17.1621 - dense_9_loss: 0.1584 - dense_14_loss: 17.0036 - val_loss: 17.2509 - val_dense_9_loss: 0.1798 - val_dense_14_loss: 17.0710\n",
            "Epoch 33/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 16.0476 - dense_9_loss: 0.1566 - dense_14_loss: 15.8910 - val_loss: 16.1834 - val_dense_9_loss: 0.1772 - val_dense_14_loss: 16.0062\n",
            "Epoch 34/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 15.0591 - dense_9_loss: 0.1547 - dense_14_loss: 14.9044 - val_loss: 15.2367 - val_dense_9_loss: 0.1748 - val_dense_14_loss: 15.0620\n",
            "Epoch 35/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 14.1831 - dense_9_loss: 0.1527 - dense_14_loss: 14.0304 - val_loss: 14.4055 - val_dense_9_loss: 0.1736 - val_dense_14_loss: 14.2319\n",
            "Epoch 36/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 13.4129 - dense_9_loss: 0.1513 - dense_14_loss: 13.2616 - val_loss: 13.6694 - val_dense_9_loss: 0.1714 - val_dense_14_loss: 13.4981\n",
            "Epoch 37/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 12.7357 - dense_9_loss: 0.1503 - dense_14_loss: 12.5854 - val_loss: 13.0312 - val_dense_9_loss: 0.1754 - val_dense_14_loss: 12.8558\n",
            "Epoch 38/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 12.1447 - dense_9_loss: 0.1494 - dense_14_loss: 11.9953 - val_loss: 12.4561 - val_dense_9_loss: 0.1672 - val_dense_14_loss: 12.2890\n",
            "Epoch 39/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 11.6264 - dense_9_loss: 0.1470 - dense_14_loss: 11.4795 - val_loss: 11.9597 - val_dense_9_loss: 0.1652 - val_dense_14_loss: 11.7944\n",
            "Epoch 40/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 11.1763 - dense_9_loss: 0.1454 - dense_14_loss: 11.0309 - val_loss: 11.5345 - val_dense_9_loss: 0.1641 - val_dense_14_loss: 11.3704\n",
            "Epoch 41/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 10.7883 - dense_9_loss: 0.1444 - dense_14_loss: 10.6440 - val_loss: 11.1658 - val_dense_9_loss: 0.1658 - val_dense_14_loss: 11.0001\n",
            "Epoch 42/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 10.4533 - dense_9_loss: 0.1441 - dense_14_loss: 10.3092 - val_loss: 10.8426 - val_dense_9_loss: 0.1605 - val_dense_14_loss: 10.6822\n",
            "Epoch 43/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 10.1633 - dense_9_loss: 0.1412 - dense_14_loss: 10.0221 - val_loss: 10.5655 - val_dense_9_loss: 0.1626 - val_dense_14_loss: 10.4029\n",
            "Epoch 44/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 9.9167 - dense_9_loss: 0.1418 - dense_14_loss: 9.7749 - val_loss: 10.3239 - val_dense_9_loss: 0.1570 - val_dense_14_loss: 10.1668\n",
            "Epoch 45/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 9.7023 - dense_9_loss: 0.1397 - dense_14_loss: 9.5626 - val_loss: 10.1202 - val_dense_9_loss: 0.1561 - val_dense_14_loss: 9.9641\n",
            "Epoch 46/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 9.5169 - dense_9_loss: 0.1375 - dense_14_loss: 9.3794 - val_loss: 9.9373 - val_dense_9_loss: 0.1543 - val_dense_14_loss: 9.7829\n",
            "Epoch 47/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 9.3484 - dense_9_loss: 0.1384 - dense_14_loss: 9.2101 - val_loss: 9.7610 - val_dense_9_loss: 0.1542 - val_dense_14_loss: 9.6068\n",
            "Epoch 48/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 9.1848 - dense_9_loss: 0.1366 - dense_14_loss: 9.0483 - val_loss: 9.5912 - val_dense_9_loss: 0.1524 - val_dense_14_loss: 9.4388\n",
            "Epoch 49/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 9.0131 - dense_9_loss: 0.1362 - dense_14_loss: 8.8768 - val_loss: 9.3827 - val_dense_9_loss: 0.1545 - val_dense_14_loss: 9.2282\n",
            "Epoch 50/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 8.7751 - dense_9_loss: 0.1370 - dense_14_loss: 8.6381 - val_loss: 9.1008 - val_dense_9_loss: 0.1520 - val_dense_14_loss: 8.9488\n",
            "Epoch 51/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 8.4962 - dense_9_loss: 0.1358 - dense_14_loss: 8.3604 - val_loss: 8.7903 - val_dense_9_loss: 0.1507 - val_dense_14_loss: 8.6396\n",
            "Epoch 52/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 8.1889 - dense_9_loss: 0.1357 - dense_14_loss: 8.0532 - val_loss: 8.4474 - val_dense_9_loss: 0.1505 - val_dense_14_loss: 8.2970\n",
            "Epoch 53/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 7.8176 - dense_9_loss: 0.1377 - dense_14_loss: 7.6799 - val_loss: 7.9775 - val_dense_9_loss: 0.1537 - val_dense_14_loss: 7.8238\n",
            "Epoch 54/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 7.3456 - dense_9_loss: 0.1414 - dense_14_loss: 7.2042 - val_loss: 7.4549 - val_dense_9_loss: 0.1537 - val_dense_14_loss: 7.3012\n",
            "Epoch 55/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 6.8196 - dense_9_loss: 0.1509 - dense_14_loss: 6.6688 - val_loss: 6.8378 - val_dense_9_loss: 0.1668 - val_dense_14_loss: 6.6710\n",
            "Epoch 56/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 6.1806 - dense_9_loss: 0.1632 - dense_14_loss: 6.0174 - val_loss: 6.0846 - val_dense_9_loss: 0.1760 - val_dense_14_loss: 5.9086\n",
            "Epoch 57/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 5.4324 - dense_9_loss: 0.1786 - dense_14_loss: 5.2537 - val_loss: 5.2295 - val_dense_9_loss: 0.1906 - val_dense_14_loss: 5.0389\n",
            "Epoch 58/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 4.5803 - dense_9_loss: 0.1848 - dense_14_loss: 4.3955 - val_loss: 4.3236 - val_dense_9_loss: 0.1816 - val_dense_14_loss: 4.1420\n",
            "Epoch 59/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.8384 - dense_9_loss: 0.1669 - dense_14_loss: 3.6715 - val_loss: 3.6674 - val_dense_9_loss: 0.1575 - val_dense_14_loss: 3.5100\n",
            "Epoch 60/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 3.3264 - dense_9_loss: 0.1442 - dense_14_loss: 3.1822 - val_loss: 3.2414 - val_dense_9_loss: 0.1424 - val_dense_14_loss: 3.0990\n",
            "Epoch 61/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 2.9870 - dense_9_loss: 0.1307 - dense_14_loss: 2.8563 - val_loss: 2.9512 - val_dense_9_loss: 0.1416 - val_dense_14_loss: 2.8095\n",
            "Epoch 62/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 2.7386 - dense_9_loss: 0.1275 - dense_14_loss: 2.6111 - val_loss: 2.7142 - val_dense_9_loss: 0.1385 - val_dense_14_loss: 2.5757\n",
            "Epoch 63/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 2.5277 - dense_9_loss: 0.1266 - dense_14_loss: 2.4011 - val_loss: 2.5058 - val_dense_9_loss: 0.1362 - val_dense_14_loss: 2.3696\n",
            "Epoch 64/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 2.3394 - dense_9_loss: 0.1241 - dense_14_loss: 2.2153 - val_loss: 2.3225 - val_dense_9_loss: 0.1346 - val_dense_14_loss: 2.1879\n",
            "Epoch 65/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 2.1710 - dense_9_loss: 0.1240 - dense_14_loss: 2.0470 - val_loss: 2.1554 - val_dense_9_loss: 0.1338 - val_dense_14_loss: 2.0216\n",
            "Epoch 66/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 2.0165 - dense_9_loss: 0.1211 - dense_14_loss: 1.8954 - val_loss: 2.0088 - val_dense_9_loss: 0.1309 - val_dense_14_loss: 1.8779\n",
            "Epoch 67/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.8819 - dense_9_loss: 0.1208 - dense_14_loss: 1.7611 - val_loss: 1.8672 - val_dense_9_loss: 0.1302 - val_dense_14_loss: 1.7371\n",
            "Epoch 68/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.7542 - dense_9_loss: 0.1209 - dense_14_loss: 1.6334 - val_loss: 1.7491 - val_dense_9_loss: 0.1301 - val_dense_14_loss: 1.6190\n",
            "Epoch 69/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.6334 - dense_9_loss: 0.1149 - dense_14_loss: 1.5185 - val_loss: 1.6327 - val_dense_9_loss: 0.1308 - val_dense_14_loss: 1.5020\n",
            "Epoch 70/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.5310 - dense_9_loss: 0.1149 - dense_14_loss: 1.4161 - val_loss: 1.5288 - val_dense_9_loss: 0.1288 - val_dense_14_loss: 1.4000\n",
            "Epoch 71/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 1.4347 - dense_9_loss: 0.1126 - dense_14_loss: 1.3222 - val_loss: 1.4295 - val_dense_9_loss: 0.1215 - val_dense_14_loss: 1.3080\n",
            "Epoch 72/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.3490 - dense_9_loss: 0.1099 - dense_14_loss: 1.2391 - val_loss: 1.3483 - val_dense_9_loss: 0.1239 - val_dense_14_loss: 1.2244\n",
            "Epoch 73/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.2720 - dense_9_loss: 0.1098 - dense_14_loss: 1.1622 - val_loss: 1.2694 - val_dense_9_loss: 0.1183 - val_dense_14_loss: 1.1512\n",
            "Epoch 74/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.2008 - dense_9_loss: 0.1078 - dense_14_loss: 1.0930 - val_loss: 1.2031 - val_dense_9_loss: 0.1208 - val_dense_14_loss: 1.0823\n",
            "Epoch 75/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.1367 - dense_9_loss: 0.1073 - dense_14_loss: 1.0294 - val_loss: 1.1350 - val_dense_9_loss: 0.1197 - val_dense_14_loss: 1.0153\n",
            "Epoch 76/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.0738 - dense_9_loss: 0.1036 - dense_14_loss: 0.9703 - val_loss: 1.0676 - val_dense_9_loss: 0.1122 - val_dense_14_loss: 0.9554\n",
            "Epoch 77/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 1.0197 - dense_9_loss: 0.1030 - dense_14_loss: 0.9167 - val_loss: 1.0277 - val_dense_9_loss: 0.1236 - val_dense_14_loss: 0.9041\n",
            "Epoch 78/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9677 - dense_9_loss: 0.1015 - dense_14_loss: 0.8662 - val_loss: 0.9591 - val_dense_9_loss: 0.1087 - val_dense_14_loss: 0.8505\n",
            "Epoch 79/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.9161 - dense_9_loss: 0.0980 - dense_14_loss: 0.8180 - val_loss: 0.9105 - val_dense_9_loss: 0.1072 - val_dense_14_loss: 0.8033\n",
            "Epoch 80/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8716 - dense_9_loss: 0.0967 - dense_14_loss: 0.7750 - val_loss: 0.8734 - val_dense_9_loss: 0.1055 - val_dense_14_loss: 0.7679\n",
            "Epoch 81/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8351 - dense_9_loss: 0.0967 - dense_14_loss: 0.7384 - val_loss: 0.8277 - val_dense_9_loss: 0.1072 - val_dense_14_loss: 0.7206\n",
            "Epoch 82/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7904 - dense_9_loss: 0.0938 - dense_14_loss: 0.6966 - val_loss: 0.7848 - val_dense_9_loss: 0.1036 - val_dense_14_loss: 0.6812\n",
            "Epoch 83/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7535 - dense_9_loss: 0.0933 - dense_14_loss: 0.6602 - val_loss: 0.7469 - val_dense_9_loss: 0.1011 - val_dense_14_loss: 0.6458\n",
            "Epoch 84/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.7182 - dense_9_loss: 0.0915 - dense_14_loss: 0.6267 - val_loss: 0.7167 - val_dense_9_loss: 0.1008 - val_dense_14_loss: 0.6159\n",
            "Epoch 85/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6845 - dense_9_loss: 0.0893 - dense_14_loss: 0.5952 - val_loss: 0.6823 - val_dense_9_loss: 0.0977 - val_dense_14_loss: 0.5846\n",
            "Epoch 86/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6547 - dense_9_loss: 0.0886 - dense_14_loss: 0.5661 - val_loss: 0.6447 - val_dense_9_loss: 0.0948 - val_dense_14_loss: 0.5499\n",
            "Epoch 87/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.6250 - dense_9_loss: 0.0873 - dense_14_loss: 0.5377 - val_loss: 0.6198 - val_dense_9_loss: 0.0967 - val_dense_14_loss: 0.5232\n",
            "Epoch 88/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.5974 - dense_9_loss: 0.0857 - dense_14_loss: 0.5117 - val_loss: 0.5893 - val_dense_9_loss: 0.0924 - val_dense_14_loss: 0.4969\n",
            "Epoch 89/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.5741 - dense_9_loss: 0.0849 - dense_14_loss: 0.4892 - val_loss: 0.5663 - val_dense_9_loss: 0.0936 - val_dense_14_loss: 0.4727\n",
            "Epoch 90/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.5497 - dense_9_loss: 0.0820 - dense_14_loss: 0.4678 - val_loss: 0.5362 - val_dense_9_loss: 0.0873 - val_dense_14_loss: 0.4490\n",
            "Epoch 91/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.5251 - dense_9_loss: 0.0811 - dense_14_loss: 0.4440 - val_loss: 0.5133 - val_dense_9_loss: 0.0859 - val_dense_14_loss: 0.4274\n",
            "Epoch 92/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.5088 - dense_9_loss: 0.0827 - dense_14_loss: 0.4261 - val_loss: 0.5087 - val_dense_9_loss: 0.0890 - val_dense_14_loss: 0.4198\n",
            "Epoch 93/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.4840 - dense_9_loss: 0.0788 - dense_14_loss: 0.4053 - val_loss: 0.4753 - val_dense_9_loss: 0.0843 - val_dense_14_loss: 0.3910\n",
            "Epoch 94/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.4653 - dense_9_loss: 0.0770 - dense_14_loss: 0.3883 - val_loss: 0.4533 - val_dense_9_loss: 0.0809 - val_dense_14_loss: 0.3724\n",
            "Epoch 95/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.4466 - dense_9_loss: 0.0737 - dense_14_loss: 0.3728 - val_loss: 0.4330 - val_dense_9_loss: 0.0767 - val_dense_14_loss: 0.3563\n",
            "Epoch 96/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.4295 - dense_9_loss: 0.0717 - dense_14_loss: 0.3578 - val_loss: 0.4248 - val_dense_9_loss: 0.0778 - val_dense_14_loss: 0.3470\n",
            "Epoch 97/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.4135 - dense_9_loss: 0.0711 - dense_14_loss: 0.3424 - val_loss: 0.4019 - val_dense_9_loss: 0.0744 - val_dense_14_loss: 0.3275\n",
            "Epoch 98/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.3970 - dense_9_loss: 0.0682 - dense_14_loss: 0.3288 - val_loss: 0.3839 - val_dense_9_loss: 0.0709 - val_dense_14_loss: 0.3130\n",
            "Epoch 99/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.3835 - dense_9_loss: 0.0666 - dense_14_loss: 0.3169 - val_loss: 0.3728 - val_dense_9_loss: 0.0697 - val_dense_14_loss: 0.3031\n",
            "Epoch 100/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.3691 - dense_9_loss: 0.0645 - dense_14_loss: 0.3046 - val_loss: 0.3574 - val_dense_9_loss: 0.0666 - val_dense_14_loss: 0.2908\n",
            "Epoch 101/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.3548 - dense_9_loss: 0.0627 - dense_14_loss: 0.2921 - val_loss: 0.3403 - val_dense_9_loss: 0.0628 - val_dense_14_loss: 0.2775\n",
            "Epoch 102/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.3435 - dense_9_loss: 0.0611 - dense_14_loss: 0.2824 - val_loss: 0.3286 - val_dense_9_loss: 0.0605 - val_dense_14_loss: 0.2682\n",
            "Epoch 103/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.3325 - dense_9_loss: 0.0607 - dense_14_loss: 0.2718 - val_loss: 0.3162 - val_dense_9_loss: 0.0588 - val_dense_14_loss: 0.2573\n",
            "Epoch 104/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.3228 - dense_9_loss: 0.0591 - dense_14_loss: 0.2637 - val_loss: 0.3076 - val_dense_9_loss: 0.0582 - val_dense_14_loss: 0.2494\n",
            "Epoch 105/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.3114 - dense_9_loss: 0.0584 - dense_14_loss: 0.2531 - val_loss: 0.2965 - val_dense_9_loss: 0.0571 - val_dense_14_loss: 0.2394\n",
            "Epoch 106/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.3041 - dense_9_loss: 0.0591 - dense_14_loss: 0.2450 - val_loss: 0.2868 - val_dense_9_loss: 0.0566 - val_dense_14_loss: 0.2302\n",
            "Epoch 107/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.2945 - dense_9_loss: 0.0574 - dense_14_loss: 0.2371 - val_loss: 0.2846 - val_dense_9_loss: 0.0582 - val_dense_14_loss: 0.2264\n",
            "Epoch 108/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2870 - dense_9_loss: 0.0581 - dense_14_loss: 0.2290 - val_loss: 0.2723 - val_dense_9_loss: 0.0579 - val_dense_14_loss: 0.2143\n",
            "Epoch 109/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2803 - dense_9_loss: 0.0581 - dense_14_loss: 0.2222 - val_loss: 0.2642 - val_dense_9_loss: 0.0573 - val_dense_14_loss: 0.2069\n",
            "Epoch 110/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2721 - dense_9_loss: 0.0571 - dense_14_loss: 0.2150 - val_loss: 0.2559 - val_dense_9_loss: 0.0554 - val_dense_14_loss: 0.2005\n",
            "Epoch 111/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2653 - dense_9_loss: 0.0577 - dense_14_loss: 0.2076 - val_loss: 0.2504 - val_dense_9_loss: 0.0559 - val_dense_14_loss: 0.1945\n",
            "Epoch 112/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2592 - dense_9_loss: 0.0580 - dense_14_loss: 0.2012 - val_loss: 0.2418 - val_dense_9_loss: 0.0547 - val_dense_14_loss: 0.1871\n",
            "Epoch 113/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2511 - dense_9_loss: 0.0567 - dense_14_loss: 0.1943 - val_loss: 0.2379 - val_dense_9_loss: 0.0560 - val_dense_14_loss: 0.1820\n",
            "Epoch 114/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2453 - dense_9_loss: 0.0567 - dense_14_loss: 0.1885 - val_loss: 0.2402 - val_dense_9_loss: 0.0591 - val_dense_14_loss: 0.1811\n",
            "Epoch 115/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2416 - dense_9_loss: 0.0575 - dense_14_loss: 0.1840 - val_loss: 0.2260 - val_dense_9_loss: 0.0557 - val_dense_14_loss: 0.1703\n",
            "Epoch 116/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2371 - dense_9_loss: 0.0582 - dense_14_loss: 0.1789 - val_loss: 0.2277 - val_dense_9_loss: 0.0545 - val_dense_14_loss: 0.1733\n",
            "Epoch 117/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2311 - dense_9_loss: 0.0573 - dense_14_loss: 0.1738 - val_loss: 0.2164 - val_dense_9_loss: 0.0559 - val_dense_14_loss: 0.1605\n",
            "Epoch 118/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.2242 - dense_9_loss: 0.0566 - dense_14_loss: 0.1676 - val_loss: 0.2152 - val_dense_9_loss: 0.0569 - val_dense_14_loss: 0.1583\n",
            "Epoch 119/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2200 - dense_9_loss: 0.0569 - dense_14_loss: 0.1631 - val_loss: 0.2062 - val_dense_9_loss: 0.0548 - val_dense_14_loss: 0.1514\n",
            "Epoch 120/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2136 - dense_9_loss: 0.0562 - dense_14_loss: 0.1574 - val_loss: 0.2023 - val_dense_9_loss: 0.0552 - val_dense_14_loss: 0.1471\n",
            "Epoch 121/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2114 - dense_9_loss: 0.0575 - dense_14_loss: 0.1539 - val_loss: 0.1963 - val_dense_9_loss: 0.0536 - val_dense_14_loss: 0.1427\n",
            "Epoch 122/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2083 - dense_9_loss: 0.0568 - dense_14_loss: 0.1515 - val_loss: 0.1924 - val_dense_9_loss: 0.0537 - val_dense_14_loss: 0.1387\n",
            "Epoch 123/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.2027 - dense_9_loss: 0.0561 - dense_14_loss: 0.1466 - val_loss: 0.1874 - val_dense_9_loss: 0.0529 - val_dense_14_loss: 0.1345\n",
            "Epoch 124/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1985 - dense_9_loss: 0.0564 - dense_14_loss: 0.1420 - val_loss: 0.1879 - val_dense_9_loss: 0.0556 - val_dense_14_loss: 0.1323\n",
            "Epoch 125/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1940 - dense_9_loss: 0.0554 - dense_14_loss: 0.1386 - val_loss: 0.1884 - val_dense_9_loss: 0.0575 - val_dense_14_loss: 0.1310\n",
            "Epoch 126/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1926 - dense_9_loss: 0.0563 - dense_14_loss: 0.1363 - val_loss: 0.1785 - val_dense_9_loss: 0.0529 - val_dense_14_loss: 0.1257\n",
            "Epoch 127/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1882 - dense_9_loss: 0.0562 - dense_14_loss: 0.1320 - val_loss: 0.1807 - val_dense_9_loss: 0.0532 - val_dense_14_loss: 0.1275\n",
            "Epoch 128/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1831 - dense_9_loss: 0.0548 - dense_14_loss: 0.1284 - val_loss: 0.1758 - val_dense_9_loss: 0.0542 - val_dense_14_loss: 0.1216\n",
            "Epoch 129/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1823 - dense_9_loss: 0.0554 - dense_14_loss: 0.1269 - val_loss: 0.1702 - val_dense_9_loss: 0.0526 - val_dense_14_loss: 0.1176\n",
            "Epoch 130/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1787 - dense_9_loss: 0.0551 - dense_14_loss: 0.1237 - val_loss: 0.1651 - val_dense_9_loss: 0.0525 - val_dense_14_loss: 0.1126\n",
            "Epoch 131/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1752 - dense_9_loss: 0.0546 - dense_14_loss: 0.1206 - val_loss: 0.1658 - val_dense_9_loss: 0.0550 - val_dense_14_loss: 0.1107\n",
            "Epoch 132/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1745 - dense_9_loss: 0.0565 - dense_14_loss: 0.1180 - val_loss: 0.1605 - val_dense_9_loss: 0.0526 - val_dense_14_loss: 0.1079\n",
            "Epoch 133/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1693 - dense_9_loss: 0.0550 - dense_14_loss: 0.1143 - val_loss: 0.1629 - val_dense_9_loss: 0.0537 - val_dense_14_loss: 0.1092\n",
            "Epoch 134/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1685 - dense_9_loss: 0.0551 - dense_14_loss: 0.1134 - val_loss: 0.1580 - val_dense_9_loss: 0.0521 - val_dense_14_loss: 0.1059\n",
            "Epoch 135/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1697 - dense_9_loss: 0.0556 - dense_14_loss: 0.1141 - val_loss: 0.1543 - val_dense_9_loss: 0.0522 - val_dense_14_loss: 0.1021\n",
            "Epoch 136/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1658 - dense_9_loss: 0.0567 - dense_14_loss: 0.1091 - val_loss: 0.1604 - val_dense_9_loss: 0.0600 - val_dense_14_loss: 0.1004\n",
            "Epoch 137/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1636 - dense_9_loss: 0.0575 - dense_14_loss: 0.1061 - val_loss: 0.1513 - val_dense_9_loss: 0.0517 - val_dense_14_loss: 0.0996\n",
            "Epoch 138/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1607 - dense_9_loss: 0.0556 - dense_14_loss: 0.1051 - val_loss: 0.1487 - val_dense_9_loss: 0.0535 - val_dense_14_loss: 0.0953\n",
            "Epoch 139/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1564 - dense_9_loss: 0.0542 - dense_14_loss: 0.1022 - val_loss: 0.1451 - val_dense_9_loss: 0.0512 - val_dense_14_loss: 0.0939\n",
            "Epoch 140/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1556 - dense_9_loss: 0.0550 - dense_14_loss: 0.1005 - val_loss: 0.1460 - val_dense_9_loss: 0.0522 - val_dense_14_loss: 0.0938\n",
            "Epoch 141/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1521 - dense_9_loss: 0.0540 - dense_14_loss: 0.0981 - val_loss: 0.1413 - val_dense_9_loss: 0.0514 - val_dense_14_loss: 0.0899\n",
            "Epoch 142/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1538 - dense_9_loss: 0.0558 - dense_14_loss: 0.0980 - val_loss: 0.1405 - val_dense_9_loss: 0.0511 - val_dense_14_loss: 0.0894\n",
            "Epoch 143/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1487 - dense_9_loss: 0.0539 - dense_14_loss: 0.0948 - val_loss: 0.1497 - val_dense_9_loss: 0.0578 - val_dense_14_loss: 0.0919\n",
            "Epoch 144/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1496 - dense_9_loss: 0.0552 - dense_14_loss: 0.0944 - val_loss: 0.1420 - val_dense_9_loss: 0.0534 - val_dense_14_loss: 0.0886\n",
            "Epoch 145/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1461 - dense_9_loss: 0.0540 - dense_14_loss: 0.0922 - val_loss: 0.1352 - val_dense_9_loss: 0.0510 - val_dense_14_loss: 0.0842\n",
            "Epoch 146/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1446 - dense_9_loss: 0.0538 - dense_14_loss: 0.0908 - val_loss: 0.1366 - val_dense_9_loss: 0.0535 - val_dense_14_loss: 0.0832\n",
            "Epoch 147/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1509 - dense_9_loss: 0.0555 - dense_14_loss: 0.0954 - val_loss: 0.1374 - val_dense_9_loss: 0.0532 - val_dense_14_loss: 0.0842\n",
            "Epoch 148/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1457 - dense_9_loss: 0.0547 - dense_14_loss: 0.0910 - val_loss: 0.1314 - val_dense_9_loss: 0.0511 - val_dense_14_loss: 0.0802\n",
            "Epoch 149/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1408 - dense_9_loss: 0.0540 - dense_14_loss: 0.0868 - val_loss: 0.1321 - val_dense_9_loss: 0.0528 - val_dense_14_loss: 0.0793\n",
            "Epoch 150/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1384 - dense_9_loss: 0.0531 - dense_14_loss: 0.0852 - val_loss: 0.1306 - val_dense_9_loss: 0.0512 - val_dense_14_loss: 0.0793\n",
            "Epoch 151/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1368 - dense_9_loss: 0.0531 - dense_14_loss: 0.0838 - val_loss: 0.1278 - val_dense_9_loss: 0.0508 - val_dense_14_loss: 0.0770\n",
            "Epoch 152/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1367 - dense_9_loss: 0.0532 - dense_14_loss: 0.0835 - val_loss: 0.1324 - val_dense_9_loss: 0.0505 - val_dense_14_loss: 0.0819\n",
            "Epoch 153/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1368 - dense_9_loss: 0.0544 - dense_14_loss: 0.0824 - val_loss: 0.1282 - val_dense_9_loss: 0.0532 - val_dense_14_loss: 0.0750\n",
            "Epoch 154/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1354 - dense_9_loss: 0.0543 - dense_14_loss: 0.0811 - val_loss: 0.1314 - val_dense_9_loss: 0.0535 - val_dense_14_loss: 0.0779\n",
            "Epoch 155/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1346 - dense_9_loss: 0.0541 - dense_14_loss: 0.0805 - val_loss: 0.1269 - val_dense_9_loss: 0.0511 - val_dense_14_loss: 0.0758\n",
            "Epoch 156/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1363 - dense_9_loss: 0.0539 - dense_14_loss: 0.0824 - val_loss: 0.1260 - val_dense_9_loss: 0.0531 - val_dense_14_loss: 0.0729\n",
            "Epoch 157/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1359 - dense_9_loss: 0.0559 - dense_14_loss: 0.0800 - val_loss: 0.1352 - val_dense_9_loss: 0.0610 - val_dense_14_loss: 0.0742\n",
            "Epoch 158/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1343 - dense_9_loss: 0.0543 - dense_14_loss: 0.0800 - val_loss: 0.1225 - val_dense_9_loss: 0.0499 - val_dense_14_loss: 0.0726\n",
            "Epoch 159/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1296 - dense_9_loss: 0.0532 - dense_14_loss: 0.0763 - val_loss: 0.1202 - val_dense_9_loss: 0.0499 - val_dense_14_loss: 0.0702\n",
            "Epoch 160/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1298 - dense_9_loss: 0.0535 - dense_14_loss: 0.0763 - val_loss: 0.1208 - val_dense_9_loss: 0.0496 - val_dense_14_loss: 0.0711\n",
            "Epoch 161/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1279 - dense_9_loss: 0.0528 - dense_14_loss: 0.0751 - val_loss: 0.1285 - val_dense_9_loss: 0.0519 - val_dense_14_loss: 0.0766\n",
            "Epoch 162/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1273 - dense_9_loss: 0.0527 - dense_14_loss: 0.0746 - val_loss: 0.1204 - val_dense_9_loss: 0.0511 - val_dense_14_loss: 0.0693\n",
            "Epoch 163/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1265 - dense_9_loss: 0.0529 - dense_14_loss: 0.0735 - val_loss: 0.1185 - val_dense_9_loss: 0.0510 - val_dense_14_loss: 0.0675\n",
            "Epoch 164/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1255 - dense_9_loss: 0.0529 - dense_14_loss: 0.0726 - val_loss: 0.1200 - val_dense_9_loss: 0.0507 - val_dense_14_loss: 0.0692\n",
            "Epoch 165/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1255 - dense_9_loss: 0.0530 - dense_14_loss: 0.0725 - val_loss: 0.1284 - val_dense_9_loss: 0.0599 - val_dense_14_loss: 0.0685\n",
            "Epoch 166/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1289 - dense_9_loss: 0.0548 - dense_14_loss: 0.0741 - val_loss: 0.1212 - val_dense_9_loss: 0.0496 - val_dense_14_loss: 0.0716\n",
            "Epoch 167/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1262 - dense_9_loss: 0.0527 - dense_14_loss: 0.0734 - val_loss: 0.1215 - val_dense_9_loss: 0.0546 - val_dense_14_loss: 0.0669\n",
            "Epoch 168/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1255 - dense_9_loss: 0.0539 - dense_14_loss: 0.0716 - val_loss: 0.1181 - val_dense_9_loss: 0.0493 - val_dense_14_loss: 0.0688\n",
            "Epoch 169/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1253 - dense_9_loss: 0.0553 - dense_14_loss: 0.0700 - val_loss: 0.1163 - val_dense_9_loss: 0.0505 - val_dense_14_loss: 0.0658\n",
            "Epoch 170/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1221 - dense_9_loss: 0.0527 - dense_14_loss: 0.0694 - val_loss: 0.1252 - val_dense_9_loss: 0.0556 - val_dense_14_loss: 0.0695\n",
            "Epoch 171/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1246 - dense_9_loss: 0.0532 - dense_14_loss: 0.0715 - val_loss: 0.1132 - val_dense_9_loss: 0.0496 - val_dense_14_loss: 0.0637\n",
            "Epoch 172/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1201 - dense_9_loss: 0.0519 - dense_14_loss: 0.0682 - val_loss: 0.1160 - val_dense_9_loss: 0.0502 - val_dense_14_loss: 0.0658\n",
            "Epoch 173/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1231 - dense_9_loss: 0.0544 - dense_14_loss: 0.0687 - val_loss: 0.1130 - val_dense_9_loss: 0.0490 - val_dense_14_loss: 0.0640\n",
            "Epoch 174/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1203 - dense_9_loss: 0.0523 - dense_14_loss: 0.0680 - val_loss: 0.1121 - val_dense_9_loss: 0.0490 - val_dense_14_loss: 0.0630\n",
            "Epoch 175/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1210 - dense_9_loss: 0.0534 - dense_14_loss: 0.0676 - val_loss: 0.1126 - val_dense_9_loss: 0.0503 - val_dense_14_loss: 0.0624\n",
            "Epoch 176/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1206 - dense_9_loss: 0.0537 - dense_14_loss: 0.0669 - val_loss: 0.1111 - val_dense_9_loss: 0.0489 - val_dense_14_loss: 0.0621\n",
            "Epoch 177/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1220 - dense_9_loss: 0.0550 - dense_14_loss: 0.0670 - val_loss: 0.1100 - val_dense_9_loss: 0.0490 - val_dense_14_loss: 0.0610\n",
            "Epoch 178/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1182 - dense_9_loss: 0.0523 - dense_14_loss: 0.0658 - val_loss: 0.1120 - val_dense_9_loss: 0.0511 - val_dense_14_loss: 0.0609\n",
            "Epoch 179/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1185 - dense_9_loss: 0.0525 - dense_14_loss: 0.0660 - val_loss: 0.1104 - val_dense_9_loss: 0.0489 - val_dense_14_loss: 0.0615\n",
            "Epoch 180/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1159 - dense_9_loss: 0.0516 - dense_14_loss: 0.0643 - val_loss: 0.1098 - val_dense_9_loss: 0.0487 - val_dense_14_loss: 0.0610\n",
            "Epoch 181/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1166 - dense_9_loss: 0.0524 - dense_14_loss: 0.0642 - val_loss: 0.1118 - val_dense_9_loss: 0.0502 - val_dense_14_loss: 0.0617\n",
            "Epoch 182/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1182 - dense_9_loss: 0.0530 - dense_14_loss: 0.0653 - val_loss: 0.1231 - val_dense_9_loss: 0.0533 - val_dense_14_loss: 0.0698\n",
            "Epoch 183/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1165 - dense_9_loss: 0.0519 - dense_14_loss: 0.0646 - val_loss: 0.1087 - val_dense_9_loss: 0.0485 - val_dense_14_loss: 0.0601\n",
            "Epoch 184/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1155 - dense_9_loss: 0.0517 - dense_14_loss: 0.0638 - val_loss: 0.1096 - val_dense_9_loss: 0.0503 - val_dense_14_loss: 0.0593\n",
            "Epoch 185/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1158 - dense_9_loss: 0.0519 - dense_14_loss: 0.0639 - val_loss: 0.1086 - val_dense_9_loss: 0.0498 - val_dense_14_loss: 0.0588\n",
            "Epoch 186/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1150 - dense_9_loss: 0.0524 - dense_14_loss: 0.0626 - val_loss: 0.1074 - val_dense_9_loss: 0.0490 - val_dense_14_loss: 0.0584\n",
            "Epoch 187/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1155 - dense_9_loss: 0.0525 - dense_14_loss: 0.0630 - val_loss: 0.1074 - val_dense_9_loss: 0.0484 - val_dense_14_loss: 0.0590\n",
            "Epoch 188/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1145 - dense_9_loss: 0.0522 - dense_14_loss: 0.0623 - val_loss: 0.1100 - val_dense_9_loss: 0.0484 - val_dense_14_loss: 0.0616\n",
            "Epoch 189/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1150 - dense_9_loss: 0.0520 - dense_14_loss: 0.0630 - val_loss: 0.1171 - val_dense_9_loss: 0.0494 - val_dense_14_loss: 0.0677\n",
            "Epoch 190/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1141 - dense_9_loss: 0.0517 - dense_14_loss: 0.0624 - val_loss: 0.1063 - val_dense_9_loss: 0.0483 - val_dense_14_loss: 0.0580\n",
            "Epoch 191/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1127 - dense_9_loss: 0.0513 - dense_14_loss: 0.0614 - val_loss: 0.1124 - val_dense_9_loss: 0.0507 - val_dense_14_loss: 0.0618\n",
            "Epoch 192/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1138 - dense_9_loss: 0.0515 - dense_14_loss: 0.0623 - val_loss: 0.1098 - val_dense_9_loss: 0.0482 - val_dense_14_loss: 0.0617\n",
            "Epoch 193/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1140 - dense_9_loss: 0.0523 - dense_14_loss: 0.0617 - val_loss: 0.1087 - val_dense_9_loss: 0.0515 - val_dense_14_loss: 0.0572\n",
            "Epoch 194/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1122 - dense_9_loss: 0.0510 - dense_14_loss: 0.0612 - val_loss: 0.1054 - val_dense_9_loss: 0.0484 - val_dense_14_loss: 0.0570\n",
            "Epoch 195/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1146 - dense_9_loss: 0.0519 - dense_14_loss: 0.0626 - val_loss: 0.1067 - val_dense_9_loss: 0.0482 - val_dense_14_loss: 0.0585\n",
            "Epoch 196/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1107 - dense_9_loss: 0.0508 - dense_14_loss: 0.0599 - val_loss: 0.1047 - val_dense_9_loss: 0.0486 - val_dense_14_loss: 0.0561\n",
            "Epoch 197/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1124 - dense_9_loss: 0.0515 - dense_14_loss: 0.0609 - val_loss: 0.1053 - val_dense_9_loss: 0.0488 - val_dense_14_loss: 0.0564\n",
            "Epoch 198/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1105 - dense_9_loss: 0.0506 - dense_14_loss: 0.0599 - val_loss: 0.1083 - val_dense_9_loss: 0.0508 - val_dense_14_loss: 0.0576\n",
            "Epoch 199/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1112 - dense_9_loss: 0.0514 - dense_14_loss: 0.0599 - val_loss: 0.1074 - val_dense_9_loss: 0.0512 - val_dense_14_loss: 0.0562\n",
            "Epoch 200/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1099 - dense_9_loss: 0.0509 - dense_14_loss: 0.0590 - val_loss: 0.1035 - val_dense_9_loss: 0.0478 - val_dense_14_loss: 0.0556\n",
            "Epoch 201/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1095 - dense_9_loss: 0.0505 - dense_14_loss: 0.0591 - val_loss: 0.1067 - val_dense_9_loss: 0.0490 - val_dense_14_loss: 0.0577\n",
            "Epoch 202/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1106 - dense_9_loss: 0.0510 - dense_14_loss: 0.0596 - val_loss: 0.1049 - val_dense_9_loss: 0.0487 - val_dense_14_loss: 0.0561\n",
            "Epoch 203/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1097 - dense_9_loss: 0.0512 - dense_14_loss: 0.0586 - val_loss: 0.1049 - val_dense_9_loss: 0.0494 - val_dense_14_loss: 0.0554\n",
            "Epoch 204/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1147 - dense_9_loss: 0.0538 - dense_14_loss: 0.0609 - val_loss: 0.1153 - val_dense_9_loss: 0.0561 - val_dense_14_loss: 0.0591\n",
            "Epoch 205/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1103 - dense_9_loss: 0.0519 - dense_14_loss: 0.0584 - val_loss: 0.1033 - val_dense_9_loss: 0.0488 - val_dense_14_loss: 0.0545\n",
            "Epoch 206/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1085 - dense_9_loss: 0.0505 - dense_14_loss: 0.0580 - val_loss: 0.1025 - val_dense_9_loss: 0.0476 - val_dense_14_loss: 0.0549\n",
            "Epoch 207/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1107 - dense_9_loss: 0.0512 - dense_14_loss: 0.0595 - val_loss: 0.1072 - val_dense_9_loss: 0.0524 - val_dense_14_loss: 0.0548\n",
            "Epoch 208/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1118 - dense_9_loss: 0.0523 - dense_14_loss: 0.0595 - val_loss: 0.1032 - val_dense_9_loss: 0.0480 - val_dense_14_loss: 0.0552\n",
            "Epoch 209/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1082 - dense_9_loss: 0.0508 - dense_14_loss: 0.0574 - val_loss: 0.1042 - val_dense_9_loss: 0.0493 - val_dense_14_loss: 0.0549\n",
            "Epoch 210/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1099 - dense_9_loss: 0.0513 - dense_14_loss: 0.0586 - val_loss: 0.1023 - val_dense_9_loss: 0.0476 - val_dense_14_loss: 0.0548\n",
            "Epoch 211/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1085 - dense_9_loss: 0.0505 - dense_14_loss: 0.0579 - val_loss: 0.1044 - val_dense_9_loss: 0.0481 - val_dense_14_loss: 0.0563\n",
            "Epoch 212/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1074 - dense_9_loss: 0.0501 - dense_14_loss: 0.0573 - val_loss: 0.1016 - val_dense_9_loss: 0.0483 - val_dense_14_loss: 0.0533\n",
            "Epoch 213/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1089 - dense_9_loss: 0.0514 - dense_14_loss: 0.0574 - val_loss: 0.1021 - val_dense_9_loss: 0.0477 - val_dense_14_loss: 0.0544\n",
            "Epoch 214/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1082 - dense_9_loss: 0.0507 - dense_14_loss: 0.0575 - val_loss: 0.1009 - val_dense_9_loss: 0.0474 - val_dense_14_loss: 0.0535\n",
            "Epoch 215/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1069 - dense_9_loss: 0.0501 - dense_14_loss: 0.0569 - val_loss: 0.1032 - val_dense_9_loss: 0.0480 - val_dense_14_loss: 0.0552\n",
            "Epoch 216/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1074 - dense_9_loss: 0.0506 - dense_14_loss: 0.0568 - val_loss: 0.1024 - val_dense_9_loss: 0.0485 - val_dense_14_loss: 0.0540\n",
            "Epoch 217/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1083 - dense_9_loss: 0.0512 - dense_14_loss: 0.0572 - val_loss: 0.1011 - val_dense_9_loss: 0.0478 - val_dense_14_loss: 0.0533\n",
            "Epoch 218/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1077 - dense_9_loss: 0.0508 - dense_14_loss: 0.0569 - val_loss: 0.1123 - val_dense_9_loss: 0.0561 - val_dense_14_loss: 0.0562\n",
            "Epoch 219/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1073 - dense_9_loss: 0.0509 - dense_14_loss: 0.0565 - val_loss: 0.1004 - val_dense_9_loss: 0.0476 - val_dense_14_loss: 0.0528\n",
            "Epoch 220/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1055 - dense_9_loss: 0.0497 - dense_14_loss: 0.0559 - val_loss: 0.1000 - val_dense_9_loss: 0.0474 - val_dense_14_loss: 0.0526\n",
            "Epoch 221/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1054 - dense_9_loss: 0.0497 - dense_14_loss: 0.0557 - val_loss: 0.1138 - val_dense_9_loss: 0.0549 - val_dense_14_loss: 0.0589\n",
            "Epoch 222/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1104 - dense_9_loss: 0.0519 - dense_14_loss: 0.0584 - val_loss: 0.1051 - val_dense_9_loss: 0.0497 - val_dense_14_loss: 0.0553\n",
            "Epoch 223/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1076 - dense_9_loss: 0.0511 - dense_14_loss: 0.0565 - val_loss: 0.1019 - val_dense_9_loss: 0.0489 - val_dense_14_loss: 0.0530\n",
            "Epoch 224/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1102 - dense_9_loss: 0.0514 - dense_14_loss: 0.0589 - val_loss: 0.1039 - val_dense_9_loss: 0.0471 - val_dense_14_loss: 0.0568\n",
            "Epoch 225/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1058 - dense_9_loss: 0.0501 - dense_14_loss: 0.0557 - val_loss: 0.0992 - val_dense_9_loss: 0.0472 - val_dense_14_loss: 0.0520\n",
            "Epoch 226/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1054 - dense_9_loss: 0.0499 - dense_14_loss: 0.0555 - val_loss: 0.1057 - val_dense_9_loss: 0.0532 - val_dense_14_loss: 0.0525\n",
            "Epoch 227/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1060 - dense_9_loss: 0.0506 - dense_14_loss: 0.0555 - val_loss: 0.1034 - val_dense_9_loss: 0.0476 - val_dense_14_loss: 0.0558\n",
            "Epoch 228/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1075 - dense_9_loss: 0.0512 - dense_14_loss: 0.0563 - val_loss: 0.1054 - val_dense_9_loss: 0.0480 - val_dense_14_loss: 0.0574\n",
            "Epoch 229/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1064 - dense_9_loss: 0.0498 - dense_14_loss: 0.0567 - val_loss: 0.0999 - val_dense_9_loss: 0.0476 - val_dense_14_loss: 0.0523\n",
            "Epoch 230/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1075 - dense_9_loss: 0.0500 - dense_14_loss: 0.0575 - val_loss: 0.0996 - val_dense_9_loss: 0.0475 - val_dense_14_loss: 0.0521\n",
            "Epoch 231/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1057 - dense_9_loss: 0.0502 - dense_14_loss: 0.0555 - val_loss: 0.0980 - val_dense_9_loss: 0.0468 - val_dense_14_loss: 0.0512\n",
            "Epoch 232/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1064 - dense_9_loss: 0.0513 - dense_14_loss: 0.0551 - val_loss: 0.0987 - val_dense_9_loss: 0.0476 - val_dense_14_loss: 0.0511\n",
            "Epoch 233/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1062 - dense_9_loss: 0.0505 - dense_14_loss: 0.0556 - val_loss: 0.0980 - val_dense_9_loss: 0.0467 - val_dense_14_loss: 0.0514\n",
            "Epoch 234/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1053 - dense_9_loss: 0.0499 - dense_14_loss: 0.0554 - val_loss: 0.1013 - val_dense_9_loss: 0.0479 - val_dense_14_loss: 0.0534\n",
            "Epoch 235/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1042 - dense_9_loss: 0.0493 - dense_14_loss: 0.0550 - val_loss: 0.1024 - val_dense_9_loss: 0.0479 - val_dense_14_loss: 0.0545\n",
            "Epoch 236/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1048 - dense_9_loss: 0.0500 - dense_14_loss: 0.0549 - val_loss: 0.0997 - val_dense_9_loss: 0.0467 - val_dense_14_loss: 0.0530\n",
            "Epoch 237/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1042 - dense_9_loss: 0.0496 - dense_14_loss: 0.0546 - val_loss: 0.0977 - val_dense_9_loss: 0.0467 - val_dense_14_loss: 0.0510\n",
            "Epoch 238/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1029 - dense_9_loss: 0.0490 - dense_14_loss: 0.0539 - val_loss: 0.0982 - val_dense_9_loss: 0.0465 - val_dense_14_loss: 0.0517\n",
            "Epoch 239/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1092 - dense_9_loss: 0.0504 - dense_14_loss: 0.0588 - val_loss: 0.1002 - val_dense_9_loss: 0.0494 - val_dense_14_loss: 0.0508\n",
            "Epoch 240/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1048 - dense_9_loss: 0.0502 - dense_14_loss: 0.0546 - val_loss: 0.0967 - val_dense_9_loss: 0.0464 - val_dense_14_loss: 0.0504\n",
            "Epoch 241/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1043 - dense_9_loss: 0.0503 - dense_14_loss: 0.0540 - val_loss: 0.1023 - val_dense_9_loss: 0.0467 - val_dense_14_loss: 0.0556\n",
            "Epoch 242/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1055 - dense_9_loss: 0.0490 - dense_14_loss: 0.0565 - val_loss: 0.0989 - val_dense_9_loss: 0.0464 - val_dense_14_loss: 0.0525\n",
            "Epoch 243/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1024 - dense_9_loss: 0.0491 - dense_14_loss: 0.0534 - val_loss: 0.0986 - val_dense_9_loss: 0.0467 - val_dense_14_loss: 0.0519\n",
            "Epoch 244/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1027 - dense_9_loss: 0.0489 - dense_14_loss: 0.0538 - val_loss: 0.0965 - val_dense_9_loss: 0.0463 - val_dense_14_loss: 0.0502\n",
            "Epoch 245/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1024 - dense_9_loss: 0.0489 - dense_14_loss: 0.0535 - val_loss: 0.1029 - val_dense_9_loss: 0.0510 - val_dense_14_loss: 0.0519\n",
            "Epoch 246/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1017 - dense_9_loss: 0.0488 - dense_14_loss: 0.0530 - val_loss: 0.0961 - val_dense_9_loss: 0.0460 - val_dense_14_loss: 0.0501\n",
            "Epoch 247/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1023 - dense_9_loss: 0.0489 - dense_14_loss: 0.0534 - val_loss: 0.1034 - val_dense_9_loss: 0.0512 - val_dense_14_loss: 0.0522\n",
            "Epoch 248/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1026 - dense_9_loss: 0.0488 - dense_14_loss: 0.0537 - val_loss: 0.0965 - val_dense_9_loss: 0.0464 - val_dense_14_loss: 0.0501\n",
            "Epoch 249/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1025 - dense_9_loss: 0.0486 - dense_14_loss: 0.0539 - val_loss: 0.1018 - val_dense_9_loss: 0.0468 - val_dense_14_loss: 0.0550\n",
            "Epoch 250/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1018 - dense_9_loss: 0.0489 - dense_14_loss: 0.0529 - val_loss: 0.0963 - val_dense_9_loss: 0.0468 - val_dense_14_loss: 0.0495\n",
            "Epoch 251/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1061 - dense_9_loss: 0.0516 - dense_14_loss: 0.0546 - val_loss: 0.1042 - val_dense_9_loss: 0.0487 - val_dense_14_loss: 0.0555\n",
            "Epoch 252/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1057 - dense_9_loss: 0.0511 - dense_14_loss: 0.0547 - val_loss: 0.1063 - val_dense_9_loss: 0.0461 - val_dense_14_loss: 0.0602\n",
            "Epoch 253/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1012 - dense_9_loss: 0.0483 - dense_14_loss: 0.0529 - val_loss: 0.1021 - val_dense_9_loss: 0.0486 - val_dense_14_loss: 0.0535\n",
            "Epoch 254/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1054 - dense_9_loss: 0.0504 - dense_14_loss: 0.0549 - val_loss: 0.0967 - val_dense_9_loss: 0.0468 - val_dense_14_loss: 0.0499\n",
            "Epoch 255/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1048 - dense_9_loss: 0.0507 - dense_14_loss: 0.0541 - val_loss: 0.0960 - val_dense_9_loss: 0.0459 - val_dense_14_loss: 0.0501\n",
            "Epoch 256/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1001 - dense_9_loss: 0.0481 - dense_14_loss: 0.0520 - val_loss: 0.0990 - val_dense_9_loss: 0.0471 - val_dense_14_loss: 0.0518\n",
            "Epoch 257/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0996 - dense_9_loss: 0.0480 - dense_14_loss: 0.0516 - val_loss: 0.0944 - val_dense_9_loss: 0.0456 - val_dense_14_loss: 0.0488\n",
            "Epoch 258/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1008 - dense_9_loss: 0.0487 - dense_14_loss: 0.0521 - val_loss: 0.0947 - val_dense_9_loss: 0.0455 - val_dense_14_loss: 0.0492\n",
            "Epoch 259/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1022 - dense_9_loss: 0.0496 - dense_14_loss: 0.0526 - val_loss: 0.1103 - val_dense_9_loss: 0.0478 - val_dense_14_loss: 0.0625\n",
            "Epoch 260/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1010 - dense_9_loss: 0.0481 - dense_14_loss: 0.0528 - val_loss: 0.0943 - val_dense_9_loss: 0.0456 - val_dense_14_loss: 0.0487\n",
            "Epoch 261/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1036 - dense_9_loss: 0.0490 - dense_14_loss: 0.0547 - val_loss: 0.0978 - val_dense_9_loss: 0.0478 - val_dense_14_loss: 0.0499\n",
            "Epoch 262/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1011 - dense_9_loss: 0.0484 - dense_14_loss: 0.0527 - val_loss: 0.1083 - val_dense_9_loss: 0.0488 - val_dense_14_loss: 0.0595\n",
            "Epoch 263/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1008 - dense_9_loss: 0.0481 - dense_14_loss: 0.0527 - val_loss: 0.0953 - val_dense_9_loss: 0.0458 - val_dense_14_loss: 0.0496\n",
            "Epoch 264/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1019 - dense_9_loss: 0.0490 - dense_14_loss: 0.0529 - val_loss: 0.1067 - val_dense_9_loss: 0.0459 - val_dense_14_loss: 0.0608\n",
            "Epoch 265/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1017 - dense_9_loss: 0.0484 - dense_14_loss: 0.0534 - val_loss: 0.0964 - val_dense_9_loss: 0.0455 - val_dense_14_loss: 0.0509\n",
            "Epoch 266/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0988 - dense_9_loss: 0.0477 - dense_14_loss: 0.0511 - val_loss: 0.0945 - val_dense_9_loss: 0.0459 - val_dense_14_loss: 0.0486\n",
            "Epoch 267/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1001 - dense_9_loss: 0.0483 - dense_14_loss: 0.0518 - val_loss: 0.0939 - val_dense_9_loss: 0.0461 - val_dense_14_loss: 0.0479\n",
            "Epoch 268/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1012 - dense_9_loss: 0.0489 - dense_14_loss: 0.0523 - val_loss: 0.0957 - val_dense_9_loss: 0.0459 - val_dense_14_loss: 0.0498\n",
            "Epoch 269/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0993 - dense_9_loss: 0.0477 - dense_14_loss: 0.0516 - val_loss: 0.0992 - val_dense_9_loss: 0.0481 - val_dense_14_loss: 0.0511\n",
            "Epoch 270/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0984 - dense_9_loss: 0.0473 - dense_14_loss: 0.0511 - val_loss: 0.0931 - val_dense_9_loss: 0.0448 - val_dense_14_loss: 0.0483\n",
            "Epoch 271/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0986 - dense_9_loss: 0.0478 - dense_14_loss: 0.0508 - val_loss: 0.0933 - val_dense_9_loss: 0.0453 - val_dense_14_loss: 0.0480\n",
            "Epoch 272/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0978 - dense_9_loss: 0.0470 - dense_14_loss: 0.0507 - val_loss: 0.0944 - val_dense_9_loss: 0.0452 - val_dense_14_loss: 0.0492\n",
            "Epoch 273/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1011 - dense_9_loss: 0.0478 - dense_14_loss: 0.0533 - val_loss: 0.0993 - val_dense_9_loss: 0.0448 - val_dense_14_loss: 0.0545\n",
            "Epoch 274/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0987 - dense_9_loss: 0.0471 - dense_14_loss: 0.0515 - val_loss: 0.0990 - val_dense_9_loss: 0.0449 - val_dense_14_loss: 0.0541\n",
            "Epoch 275/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1002 - dense_9_loss: 0.0475 - dense_14_loss: 0.0527 - val_loss: 0.0940 - val_dense_9_loss: 0.0460 - val_dense_14_loss: 0.0480\n",
            "Epoch 276/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0982 - dense_9_loss: 0.0473 - dense_14_loss: 0.0509 - val_loss: 0.0932 - val_dense_9_loss: 0.0449 - val_dense_14_loss: 0.0484\n",
            "Epoch 277/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0966 - dense_9_loss: 0.0465 - dense_14_loss: 0.0501 - val_loss: 0.0982 - val_dense_9_loss: 0.0474 - val_dense_14_loss: 0.0508\n",
            "Epoch 278/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0995 - dense_9_loss: 0.0474 - dense_14_loss: 0.0521 - val_loss: 0.0953 - val_dense_9_loss: 0.0479 - val_dense_14_loss: 0.0474\n",
            "Epoch 279/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.1055 - dense_9_loss: 0.0491 - dense_14_loss: 0.0564 - val_loss: 0.0937 - val_dense_9_loss: 0.0450 - val_dense_14_loss: 0.0487\n",
            "Epoch 280/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0975 - dense_9_loss: 0.0464 - dense_14_loss: 0.0511 - val_loss: 0.0914 - val_dense_9_loss: 0.0444 - val_dense_14_loss: 0.0470\n",
            "Epoch 281/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0973 - dense_9_loss: 0.0468 - dense_14_loss: 0.0505 - val_loss: 0.0941 - val_dense_9_loss: 0.0441 - val_dense_14_loss: 0.0500\n",
            "Epoch 282/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0993 - dense_9_loss: 0.0477 - dense_14_loss: 0.0516 - val_loss: 0.0972 - val_dense_9_loss: 0.0492 - val_dense_14_loss: 0.0480\n",
            "Epoch 283/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0982 - dense_9_loss: 0.0478 - dense_14_loss: 0.0504 - val_loss: 0.0936 - val_dense_9_loss: 0.0465 - val_dense_14_loss: 0.0471\n",
            "Epoch 284/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0963 - dense_9_loss: 0.0461 - dense_14_loss: 0.0503 - val_loss: 0.0923 - val_dense_9_loss: 0.0449 - val_dense_14_loss: 0.0474\n",
            "Epoch 285/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0969 - dense_9_loss: 0.0466 - dense_14_loss: 0.0503 - val_loss: 0.0918 - val_dense_9_loss: 0.0449 - val_dense_14_loss: 0.0469\n",
            "Epoch 286/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0957 - dense_9_loss: 0.0464 - dense_14_loss: 0.0493 - val_loss: 0.0912 - val_dense_9_loss: 0.0435 - val_dense_14_loss: 0.0477\n",
            "Epoch 287/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0971 - dense_9_loss: 0.0469 - dense_14_loss: 0.0502 - val_loss: 0.0910 - val_dense_9_loss: 0.0445 - val_dense_14_loss: 0.0465\n",
            "Epoch 288/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0969 - dense_9_loss: 0.0468 - dense_14_loss: 0.0500 - val_loss: 0.0952 - val_dense_9_loss: 0.0470 - val_dense_14_loss: 0.0482\n",
            "Epoch 289/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0961 - dense_9_loss: 0.0458 - dense_14_loss: 0.0503 - val_loss: 0.0951 - val_dense_9_loss: 0.0442 - val_dense_14_loss: 0.0509\n",
            "Epoch 290/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0947 - dense_9_loss: 0.0455 - dense_14_loss: 0.0492 - val_loss: 0.0907 - val_dense_9_loss: 0.0431 - val_dense_14_loss: 0.0476\n",
            "Epoch 291/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0963 - dense_9_loss: 0.0465 - dense_14_loss: 0.0498 - val_loss: 0.0915 - val_dense_9_loss: 0.0448 - val_dense_14_loss: 0.0467\n",
            "Epoch 292/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0962 - dense_9_loss: 0.0458 - dense_14_loss: 0.0504 - val_loss: 0.0945 - val_dense_9_loss: 0.0455 - val_dense_14_loss: 0.0490\n",
            "Epoch 293/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0976 - dense_9_loss: 0.0471 - dense_14_loss: 0.0505 - val_loss: 0.0896 - val_dense_9_loss: 0.0433 - val_dense_14_loss: 0.0463\n",
            "Epoch 294/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0951 - dense_9_loss: 0.0461 - dense_14_loss: 0.0490 - val_loss: 0.0930 - val_dense_9_loss: 0.0455 - val_dense_14_loss: 0.0475\n",
            "Epoch 295/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0974 - dense_9_loss: 0.0466 - dense_14_loss: 0.0508 - val_loss: 0.0915 - val_dense_9_loss: 0.0450 - val_dense_14_loss: 0.0466\n",
            "Epoch 296/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0981 - dense_9_loss: 0.0464 - dense_14_loss: 0.0517 - val_loss: 0.0964 - val_dense_9_loss: 0.0500 - val_dense_14_loss: 0.0464\n",
            "Epoch 297/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0952 - dense_9_loss: 0.0459 - dense_14_loss: 0.0494 - val_loss: 0.0966 - val_dense_9_loss: 0.0465 - val_dense_14_loss: 0.0501\n",
            "Epoch 298/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0942 - dense_9_loss: 0.0452 - dense_14_loss: 0.0490 - val_loss: 0.0901 - val_dense_9_loss: 0.0439 - val_dense_14_loss: 0.0462\n",
            "Epoch 299/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0933 - dense_9_loss: 0.0448 - dense_14_loss: 0.0485 - val_loss: 0.0917 - val_dense_9_loss: 0.0433 - val_dense_14_loss: 0.0484\n",
            "Epoch 300/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0942 - dense_9_loss: 0.0454 - dense_14_loss: 0.0488 - val_loss: 0.0907 - val_dense_9_loss: 0.0444 - val_dense_14_loss: 0.0463\n",
            "Epoch 301/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0934 - dense_9_loss: 0.0448 - dense_14_loss: 0.0485 - val_loss: 0.0936 - val_dense_9_loss: 0.0474 - val_dense_14_loss: 0.0461\n",
            "Epoch 302/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0931 - dense_9_loss: 0.0448 - dense_14_loss: 0.0483 - val_loss: 0.1057 - val_dense_9_loss: 0.0502 - val_dense_14_loss: 0.0555\n",
            "Epoch 303/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0936 - dense_9_loss: 0.0447 - dense_14_loss: 0.0489 - val_loss: 0.0892 - val_dense_9_loss: 0.0424 - val_dense_14_loss: 0.0467\n",
            "Epoch 304/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0922 - dense_9_loss: 0.0439 - dense_14_loss: 0.0482 - val_loss: 0.0874 - val_dense_9_loss: 0.0420 - val_dense_14_loss: 0.0454\n",
            "Epoch 305/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0928 - dense_9_loss: 0.0439 - dense_14_loss: 0.0489 - val_loss: 0.0877 - val_dense_9_loss: 0.0419 - val_dense_14_loss: 0.0457\n",
            "Epoch 306/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0949 - dense_9_loss: 0.0455 - dense_14_loss: 0.0495 - val_loss: 0.0887 - val_dense_9_loss: 0.0432 - val_dense_14_loss: 0.0455\n",
            "Epoch 307/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0922 - dense_9_loss: 0.0438 - dense_14_loss: 0.0484 - val_loss: 0.0972 - val_dense_9_loss: 0.0469 - val_dense_14_loss: 0.0503\n",
            "Epoch 308/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0937 - dense_9_loss: 0.0447 - dense_14_loss: 0.0490 - val_loss: 0.0877 - val_dense_9_loss: 0.0419 - val_dense_14_loss: 0.0458\n",
            "Epoch 309/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0930 - dense_9_loss: 0.0447 - dense_14_loss: 0.0484 - val_loss: 0.0877 - val_dense_9_loss: 0.0422 - val_dense_14_loss: 0.0454\n",
            "Epoch 310/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0921 - dense_9_loss: 0.0439 - dense_14_loss: 0.0482 - val_loss: 0.0877 - val_dense_9_loss: 0.0415 - val_dense_14_loss: 0.0462\n",
            "Epoch 311/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0930 - dense_9_loss: 0.0442 - dense_14_loss: 0.0488 - val_loss: 0.0919 - val_dense_9_loss: 0.0419 - val_dense_14_loss: 0.0500\n",
            "Epoch 312/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0941 - dense_9_loss: 0.0441 - dense_14_loss: 0.0500 - val_loss: 0.0865 - val_dense_9_loss: 0.0421 - val_dense_14_loss: 0.0443\n",
            "Epoch 313/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0900 - dense_9_loss: 0.0430 - dense_14_loss: 0.0469 - val_loss: 0.0908 - val_dense_9_loss: 0.0432 - val_dense_14_loss: 0.0476\n",
            "Epoch 314/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0904 - dense_9_loss: 0.0425 - dense_14_loss: 0.0479 - val_loss: 0.0851 - val_dense_9_loss: 0.0404 - val_dense_14_loss: 0.0447\n",
            "Epoch 315/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0890 - dense_9_loss: 0.0422 - dense_14_loss: 0.0468 - val_loss: 0.0843 - val_dense_9_loss: 0.0403 - val_dense_14_loss: 0.0440\n",
            "Epoch 316/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0891 - dense_9_loss: 0.0422 - dense_14_loss: 0.0469 - val_loss: 0.0854 - val_dense_9_loss: 0.0412 - val_dense_14_loss: 0.0441\n",
            "Epoch 317/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0888 - dense_9_loss: 0.0421 - dense_14_loss: 0.0467 - val_loss: 0.0851 - val_dense_9_loss: 0.0408 - val_dense_14_loss: 0.0443\n",
            "Epoch 318/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0899 - dense_9_loss: 0.0426 - dense_14_loss: 0.0473 - val_loss: 0.0867 - val_dense_9_loss: 0.0422 - val_dense_14_loss: 0.0445\n",
            "Epoch 319/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0898 - dense_9_loss: 0.0424 - dense_14_loss: 0.0475 - val_loss: 0.0864 - val_dense_9_loss: 0.0421 - val_dense_14_loss: 0.0443\n",
            "Epoch 320/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0904 - dense_9_loss: 0.0423 - dense_14_loss: 0.0481 - val_loss: 0.0868 - val_dense_9_loss: 0.0400 - val_dense_14_loss: 0.0468\n",
            "Epoch 321/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0871 - dense_9_loss: 0.0412 - dense_14_loss: 0.0460 - val_loss: 0.0860 - val_dense_9_loss: 0.0408 - val_dense_14_loss: 0.0452\n",
            "Epoch 322/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0942 - dense_9_loss: 0.0439 - dense_14_loss: 0.0503 - val_loss: 0.0910 - val_dense_9_loss: 0.0462 - val_dense_14_loss: 0.0448\n",
            "Epoch 323/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0914 - dense_9_loss: 0.0414 - dense_14_loss: 0.0500 - val_loss: 0.0840 - val_dense_9_loss: 0.0403 - val_dense_14_loss: 0.0437\n",
            "Epoch 324/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0884 - dense_9_loss: 0.0413 - dense_14_loss: 0.0470 - val_loss: 0.0830 - val_dense_9_loss: 0.0395 - val_dense_14_loss: 0.0435\n",
            "Epoch 325/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0862 - dense_9_loss: 0.0407 - dense_14_loss: 0.0455 - val_loss: 0.0820 - val_dense_9_loss: 0.0388 - val_dense_14_loss: 0.0431\n",
            "Epoch 326/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0888 - dense_9_loss: 0.0423 - dense_14_loss: 0.0465 - val_loss: 0.0827 - val_dense_9_loss: 0.0386 - val_dense_14_loss: 0.0442\n",
            "Epoch 327/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0884 - dense_9_loss: 0.0419 - dense_14_loss: 0.0465 - val_loss: 0.0983 - val_dense_9_loss: 0.0501 - val_dense_14_loss: 0.0482\n",
            "Epoch 328/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0896 - dense_9_loss: 0.0409 - dense_14_loss: 0.0487 - val_loss: 0.0854 - val_dense_9_loss: 0.0385 - val_dense_14_loss: 0.0469\n",
            "Epoch 329/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0900 - dense_9_loss: 0.0412 - dense_14_loss: 0.0489 - val_loss: 0.0930 - val_dense_9_loss: 0.0494 - val_dense_14_loss: 0.0435\n",
            "Epoch 330/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0858 - dense_9_loss: 0.0406 - dense_14_loss: 0.0452 - val_loss: 0.0818 - val_dense_9_loss: 0.0381 - val_dense_14_loss: 0.0437\n",
            "Epoch 331/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0848 - dense_9_loss: 0.0394 - dense_14_loss: 0.0454 - val_loss: 0.0904 - val_dense_9_loss: 0.0427 - val_dense_14_loss: 0.0477\n",
            "Epoch 332/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0893 - dense_9_loss: 0.0414 - dense_14_loss: 0.0479 - val_loss: 0.0845 - val_dense_9_loss: 0.0407 - val_dense_14_loss: 0.0438\n",
            "Epoch 333/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0849 - dense_9_loss: 0.0396 - dense_14_loss: 0.0453 - val_loss: 0.0865 - val_dense_9_loss: 0.0436 - val_dense_14_loss: 0.0429\n",
            "Epoch 334/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0880 - dense_9_loss: 0.0402 - dense_14_loss: 0.0477 - val_loss: 0.0835 - val_dense_9_loss: 0.0377 - val_dense_14_loss: 0.0457\n",
            "Epoch 335/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0844 - dense_9_loss: 0.0390 - dense_14_loss: 0.0453 - val_loss: 0.0805 - val_dense_9_loss: 0.0388 - val_dense_14_loss: 0.0417\n",
            "Epoch 336/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0829 - dense_9_loss: 0.0383 - dense_14_loss: 0.0446 - val_loss: 0.0779 - val_dense_9_loss: 0.0363 - val_dense_14_loss: 0.0416\n",
            "Epoch 337/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0819 - dense_9_loss: 0.0379 - dense_14_loss: 0.0440 - val_loss: 0.0791 - val_dense_9_loss: 0.0360 - val_dense_14_loss: 0.0431\n",
            "Epoch 338/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0816 - dense_9_loss: 0.0376 - dense_14_loss: 0.0440 - val_loss: 0.0789 - val_dense_9_loss: 0.0363 - val_dense_14_loss: 0.0426\n",
            "Epoch 339/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0833 - dense_9_loss: 0.0385 - dense_14_loss: 0.0448 - val_loss: 0.0904 - val_dense_9_loss: 0.0447 - val_dense_14_loss: 0.0456\n",
            "Epoch 340/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0865 - dense_9_loss: 0.0403 - dense_14_loss: 0.0462 - val_loss: 0.0860 - val_dense_9_loss: 0.0424 - val_dense_14_loss: 0.0436\n",
            "Epoch 341/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0806 - dense_9_loss: 0.0370 - dense_14_loss: 0.0436 - val_loss: 0.0771 - val_dense_9_loss: 0.0349 - val_dense_14_loss: 0.0421\n",
            "Epoch 342/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0806 - dense_9_loss: 0.0369 - dense_14_loss: 0.0437 - val_loss: 0.0810 - val_dense_9_loss: 0.0365 - val_dense_14_loss: 0.0445\n",
            "Epoch 343/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0799 - dense_9_loss: 0.0363 - dense_14_loss: 0.0437 - val_loss: 0.0883 - val_dense_9_loss: 0.0382 - val_dense_14_loss: 0.0501\n",
            "Epoch 344/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0804 - dense_9_loss: 0.0365 - dense_14_loss: 0.0439 - val_loss: 0.0756 - val_dense_9_loss: 0.0345 - val_dense_14_loss: 0.0411\n",
            "Epoch 345/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0807 - dense_9_loss: 0.0371 - dense_14_loss: 0.0437 - val_loss: 0.0751 - val_dense_9_loss: 0.0349 - val_dense_14_loss: 0.0402\n",
            "Epoch 346/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0788 - dense_9_loss: 0.0359 - dense_14_loss: 0.0429 - val_loss: 0.0752 - val_dense_9_loss: 0.0347 - val_dense_14_loss: 0.0405\n",
            "Epoch 347/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0779 - dense_9_loss: 0.0353 - dense_14_loss: 0.0426 - val_loss: 0.0752 - val_dense_9_loss: 0.0335 - val_dense_14_loss: 0.0416\n",
            "Epoch 348/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0796 - dense_9_loss: 0.0365 - dense_14_loss: 0.0431 - val_loss: 0.0735 - val_dense_9_loss: 0.0330 - val_dense_14_loss: 0.0405\n",
            "Epoch 349/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0759 - dense_9_loss: 0.0344 - dense_14_loss: 0.0414 - val_loss: 0.0727 - val_dense_9_loss: 0.0329 - val_dense_14_loss: 0.0398\n",
            "Epoch 350/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0783 - dense_9_loss: 0.0355 - dense_14_loss: 0.0428 - val_loss: 0.0721 - val_dense_9_loss: 0.0325 - val_dense_14_loss: 0.0396\n",
            "Epoch 351/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0787 - dense_9_loss: 0.0351 - dense_14_loss: 0.0436 - val_loss: 0.0971 - val_dense_9_loss: 0.0422 - val_dense_14_loss: 0.0549\n",
            "Epoch 352/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0778 - dense_9_loss: 0.0350 - dense_14_loss: 0.0428 - val_loss: 0.0710 - val_dense_9_loss: 0.0324 - val_dense_14_loss: 0.0386\n",
            "Epoch 353/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0769 - dense_9_loss: 0.0348 - dense_14_loss: 0.0421 - val_loss: 0.0720 - val_dense_9_loss: 0.0332 - val_dense_14_loss: 0.0388\n",
            "Epoch 354/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0760 - dense_9_loss: 0.0341 - dense_14_loss: 0.0419 - val_loss: 0.0700 - val_dense_9_loss: 0.0318 - val_dense_14_loss: 0.0382\n",
            "Epoch 355/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0727 - dense_9_loss: 0.0327 - dense_14_loss: 0.0400 - val_loss: 0.0697 - val_dense_9_loss: 0.0313 - val_dense_14_loss: 0.0384\n",
            "Epoch 356/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0736 - dense_9_loss: 0.0327 - dense_14_loss: 0.0409 - val_loss: 0.0696 - val_dense_9_loss: 0.0317 - val_dense_14_loss: 0.0379\n",
            "Epoch 357/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0728 - dense_9_loss: 0.0329 - dense_14_loss: 0.0399 - val_loss: 0.0685 - val_dense_9_loss: 0.0311 - val_dense_14_loss: 0.0374\n",
            "Epoch 358/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0717 - dense_9_loss: 0.0320 - dense_14_loss: 0.0397 - val_loss: 0.0676 - val_dense_9_loss: 0.0309 - val_dense_14_loss: 0.0367\n",
            "Epoch 359/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0700 - dense_9_loss: 0.0312 - dense_14_loss: 0.0387 - val_loss: 0.0682 - val_dense_9_loss: 0.0304 - val_dense_14_loss: 0.0378\n",
            "Epoch 360/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0744 - dense_9_loss: 0.0329 - dense_14_loss: 0.0415 - val_loss: 0.0683 - val_dense_9_loss: 0.0312 - val_dense_14_loss: 0.0370\n",
            "Epoch 361/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0706 - dense_9_loss: 0.0320 - dense_14_loss: 0.0386 - val_loss: 0.0750 - val_dense_9_loss: 0.0368 - val_dense_14_loss: 0.0382\n",
            "Epoch 362/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0712 - dense_9_loss: 0.0318 - dense_14_loss: 0.0395 - val_loss: 0.0680 - val_dense_9_loss: 0.0296 - val_dense_14_loss: 0.0385\n",
            "Epoch 363/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0687 - dense_9_loss: 0.0312 - dense_14_loss: 0.0376 - val_loss: 0.0657 - val_dense_9_loss: 0.0300 - val_dense_14_loss: 0.0357\n",
            "Epoch 364/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0697 - dense_9_loss: 0.0322 - dense_14_loss: 0.0375 - val_loss: 0.0663 - val_dense_9_loss: 0.0311 - val_dense_14_loss: 0.0352\n",
            "Epoch 365/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0683 - dense_9_loss: 0.0307 - dense_14_loss: 0.0377 - val_loss: 0.0633 - val_dense_9_loss: 0.0289 - val_dense_14_loss: 0.0344\n",
            "Epoch 366/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0670 - dense_9_loss: 0.0302 - dense_14_loss: 0.0369 - val_loss: 0.0651 - val_dense_9_loss: 0.0292 - val_dense_14_loss: 0.0359\n",
            "Epoch 367/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0652 - dense_9_loss: 0.0293 - dense_14_loss: 0.0359 - val_loss: 0.0657 - val_dense_9_loss: 0.0293 - val_dense_14_loss: 0.0364\n",
            "Epoch 368/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0663 - dense_9_loss: 0.0304 - dense_14_loss: 0.0359 - val_loss: 0.0646 - val_dense_9_loss: 0.0312 - val_dense_14_loss: 0.0334\n",
            "Epoch 369/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0643 - dense_9_loss: 0.0294 - dense_14_loss: 0.0348 - val_loss: 0.0614 - val_dense_9_loss: 0.0284 - val_dense_14_loss: 0.0330\n",
            "Epoch 370/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0654 - dense_9_loss: 0.0303 - dense_14_loss: 0.0351 - val_loss: 0.0638 - val_dense_9_loss: 0.0300 - val_dense_14_loss: 0.0338\n",
            "Epoch 371/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0629 - dense_9_loss: 0.0286 - dense_14_loss: 0.0344 - val_loss: 0.0607 - val_dense_9_loss: 0.0290 - val_dense_14_loss: 0.0317\n",
            "Epoch 372/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0648 - dense_9_loss: 0.0297 - dense_14_loss: 0.0350 - val_loss: 0.0656 - val_dense_9_loss: 0.0339 - val_dense_14_loss: 0.0317\n",
            "Epoch 373/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0640 - dense_9_loss: 0.0302 - dense_14_loss: 0.0338 - val_loss: 0.0614 - val_dense_9_loss: 0.0291 - val_dense_14_loss: 0.0323\n",
            "Epoch 374/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0607 - dense_9_loss: 0.0279 - dense_14_loss: 0.0328 - val_loss: 0.0582 - val_dense_9_loss: 0.0270 - val_dense_14_loss: 0.0312\n",
            "Epoch 375/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0618 - dense_9_loss: 0.0285 - dense_14_loss: 0.0332 - val_loss: 0.0570 - val_dense_9_loss: 0.0272 - val_dense_14_loss: 0.0299\n",
            "Epoch 376/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0588 - dense_9_loss: 0.0275 - dense_14_loss: 0.0313 - val_loss: 0.0566 - val_dense_9_loss: 0.0268 - val_dense_14_loss: 0.0298\n",
            "Epoch 377/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0578 - dense_9_loss: 0.0269 - dense_14_loss: 0.0309 - val_loss: 0.0565 - val_dense_9_loss: 0.0267 - val_dense_14_loss: 0.0298\n",
            "Epoch 378/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0585 - dense_9_loss: 0.0273 - dense_14_loss: 0.0312 - val_loss: 0.0562 - val_dense_9_loss: 0.0268 - val_dense_14_loss: 0.0294\n",
            "Epoch 379/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0569 - dense_9_loss: 0.0267 - dense_14_loss: 0.0302 - val_loss: 0.0544 - val_dense_9_loss: 0.0261 - val_dense_14_loss: 0.0283\n",
            "Epoch 380/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0567 - dense_9_loss: 0.0270 - dense_14_loss: 0.0296 - val_loss: 0.0534 - val_dense_9_loss: 0.0255 - val_dense_14_loss: 0.0279\n",
            "Epoch 381/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0561 - dense_9_loss: 0.0266 - dense_14_loss: 0.0295 - val_loss: 0.0556 - val_dense_9_loss: 0.0269 - val_dense_14_loss: 0.0288\n",
            "Epoch 382/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0580 - dense_9_loss: 0.0278 - dense_14_loss: 0.0302 - val_loss: 0.0586 - val_dense_9_loss: 0.0288 - val_dense_14_loss: 0.0298\n",
            "Epoch 383/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0540 - dense_9_loss: 0.0259 - dense_14_loss: 0.0281 - val_loss: 0.0512 - val_dense_9_loss: 0.0248 - val_dense_14_loss: 0.0264\n",
            "Epoch 384/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0534 - dense_9_loss: 0.0255 - dense_14_loss: 0.0279 - val_loss: 0.0508 - val_dense_9_loss: 0.0246 - val_dense_14_loss: 0.0262\n",
            "Epoch 385/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0526 - dense_9_loss: 0.0251 - dense_14_loss: 0.0275 - val_loss: 0.0497 - val_dense_9_loss: 0.0241 - val_dense_14_loss: 0.0255\n",
            "Epoch 386/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0512 - dense_9_loss: 0.0246 - dense_14_loss: 0.0266 - val_loss: 0.0509 - val_dense_9_loss: 0.0239 - val_dense_14_loss: 0.0270\n",
            "Epoch 387/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0516 - dense_9_loss: 0.0244 - dense_14_loss: 0.0272 - val_loss: 0.0483 - val_dense_9_loss: 0.0236 - val_dense_14_loss: 0.0247\n",
            "Epoch 388/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0495 - dense_9_loss: 0.0240 - dense_14_loss: 0.0255 - val_loss: 0.0493 - val_dense_9_loss: 0.0245 - val_dense_14_loss: 0.0248\n",
            "Epoch 389/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0504 - dense_9_loss: 0.0243 - dense_14_loss: 0.0261 - val_loss: 0.0466 - val_dense_9_loss: 0.0229 - val_dense_14_loss: 0.0236\n",
            "Epoch 390/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0489 - dense_9_loss: 0.0234 - dense_14_loss: 0.0255 - val_loss: 0.0468 - val_dense_9_loss: 0.0228 - val_dense_14_loss: 0.0240\n",
            "Epoch 391/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0478 - dense_9_loss: 0.0233 - dense_14_loss: 0.0245 - val_loss: 0.0459 - val_dense_9_loss: 0.0227 - val_dense_14_loss: 0.0232\n",
            "Epoch 392/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0484 - dense_9_loss: 0.0239 - dense_14_loss: 0.0245 - val_loss: 0.0473 - val_dense_9_loss: 0.0243 - val_dense_14_loss: 0.0230\n",
            "Epoch 393/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0465 - dense_9_loss: 0.0229 - dense_14_loss: 0.0235 - val_loss: 0.0440 - val_dense_9_loss: 0.0217 - val_dense_14_loss: 0.0223\n",
            "Epoch 394/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0451 - dense_9_loss: 0.0222 - dense_14_loss: 0.0229 - val_loss: 0.0458 - val_dense_9_loss: 0.0236 - val_dense_14_loss: 0.0222\n",
            "Epoch 395/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0450 - dense_9_loss: 0.0226 - dense_14_loss: 0.0224 - val_loss: 0.0423 - val_dense_9_loss: 0.0211 - val_dense_14_loss: 0.0212\n",
            "Epoch 396/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0462 - dense_9_loss: 0.0223 - dense_14_loss: 0.0239 - val_loss: 0.0524 - val_dense_9_loss: 0.0253 - val_dense_14_loss: 0.0271\n",
            "Epoch 397/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0427 - dense_9_loss: 0.0209 - dense_14_loss: 0.0217 - val_loss: 0.0416 - val_dense_9_loss: 0.0208 - val_dense_14_loss: 0.0208\n",
            "Epoch 398/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0421 - dense_9_loss: 0.0209 - dense_14_loss: 0.0212 - val_loss: 0.0411 - val_dense_9_loss: 0.0203 - val_dense_14_loss: 0.0208\n",
            "Epoch 399/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0413 - dense_9_loss: 0.0204 - dense_14_loss: 0.0208 - val_loss: 0.0425 - val_dense_9_loss: 0.0207 - val_dense_14_loss: 0.0219\n",
            "Epoch 400/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0410 - dense_9_loss: 0.0205 - dense_14_loss: 0.0205 - val_loss: 0.0430 - val_dense_9_loss: 0.0216 - val_dense_14_loss: 0.0214\n",
            "Epoch 401/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0402 - dense_9_loss: 0.0202 - dense_14_loss: 0.0200 - val_loss: 0.0414 - val_dense_9_loss: 0.0202 - val_dense_14_loss: 0.0212\n",
            "Epoch 402/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0402 - dense_9_loss: 0.0200 - dense_14_loss: 0.0202 - val_loss: 0.0409 - val_dense_9_loss: 0.0200 - val_dense_14_loss: 0.0208\n",
            "Epoch 403/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0406 - dense_9_loss: 0.0201 - dense_14_loss: 0.0204 - val_loss: 0.0370 - val_dense_9_loss: 0.0186 - val_dense_14_loss: 0.0183\n",
            "Epoch 404/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0381 - dense_9_loss: 0.0191 - dense_14_loss: 0.0190 - val_loss: 0.0382 - val_dense_9_loss: 0.0195 - val_dense_14_loss: 0.0187\n",
            "Epoch 405/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0385 - dense_9_loss: 0.0192 - dense_14_loss: 0.0193 - val_loss: 0.0381 - val_dense_9_loss: 0.0186 - val_dense_14_loss: 0.0194\n",
            "Epoch 406/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0368 - dense_9_loss: 0.0183 - dense_14_loss: 0.0185 - val_loss: 0.0374 - val_dense_9_loss: 0.0184 - val_dense_14_loss: 0.0190\n",
            "Epoch 407/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0371 - dense_9_loss: 0.0183 - dense_14_loss: 0.0188 - val_loss: 0.0348 - val_dense_9_loss: 0.0176 - val_dense_14_loss: 0.0172\n",
            "Epoch 408/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0365 - dense_9_loss: 0.0183 - dense_14_loss: 0.0182 - val_loss: 0.0399 - val_dense_9_loss: 0.0193 - val_dense_14_loss: 0.0205\n",
            "Epoch 409/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0371 - dense_9_loss: 0.0186 - dense_14_loss: 0.0185 - val_loss: 0.0353 - val_dense_9_loss: 0.0184 - val_dense_14_loss: 0.0169\n",
            "Epoch 410/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0356 - dense_9_loss: 0.0179 - dense_14_loss: 0.0177 - val_loss: 0.0339 - val_dense_9_loss: 0.0169 - val_dense_14_loss: 0.0170\n",
            "Epoch 411/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0355 - dense_9_loss: 0.0177 - dense_14_loss: 0.0178 - val_loss: 0.0331 - val_dense_9_loss: 0.0166 - val_dense_14_loss: 0.0165\n",
            "Epoch 412/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0341 - dense_9_loss: 0.0170 - dense_14_loss: 0.0171 - val_loss: 0.0369 - val_dense_9_loss: 0.0185 - val_dense_14_loss: 0.0185\n",
            "Epoch 413/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0340 - dense_9_loss: 0.0171 - dense_14_loss: 0.0170 - val_loss: 0.0321 - val_dense_9_loss: 0.0162 - val_dense_14_loss: 0.0158\n",
            "Epoch 414/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0347 - dense_9_loss: 0.0173 - dense_14_loss: 0.0174 - val_loss: 0.0321 - val_dense_9_loss: 0.0166 - val_dense_14_loss: 0.0156\n",
            "Epoch 415/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0323 - dense_9_loss: 0.0162 - dense_14_loss: 0.0161 - val_loss: 0.0316 - val_dense_9_loss: 0.0159 - val_dense_14_loss: 0.0157\n",
            "Epoch 416/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0323 - dense_9_loss: 0.0162 - dense_14_loss: 0.0161 - val_loss: 0.0323 - val_dense_9_loss: 0.0162 - val_dense_14_loss: 0.0161\n",
            "Epoch 417/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0320 - dense_9_loss: 0.0161 - dense_14_loss: 0.0160 - val_loss: 0.0310 - val_dense_9_loss: 0.0156 - val_dense_14_loss: 0.0154\n",
            "Epoch 418/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0323 - dense_9_loss: 0.0163 - dense_14_loss: 0.0160 - val_loss: 0.0350 - val_dense_9_loss: 0.0178 - val_dense_14_loss: 0.0172\n",
            "Epoch 419/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0316 - dense_9_loss: 0.0159 - dense_14_loss: 0.0157 - val_loss: 0.0307 - val_dense_9_loss: 0.0152 - val_dense_14_loss: 0.0155\n",
            "Epoch 420/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0325 - dense_9_loss: 0.0163 - dense_14_loss: 0.0162 - val_loss: 0.0304 - val_dense_9_loss: 0.0154 - val_dense_14_loss: 0.0149\n",
            "Epoch 421/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0301 - dense_9_loss: 0.0150 - dense_14_loss: 0.0151 - val_loss: 0.0326 - val_dense_9_loss: 0.0165 - val_dense_14_loss: 0.0161\n",
            "Epoch 422/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0303 - dense_9_loss: 0.0152 - dense_14_loss: 0.0152 - val_loss: 0.0293 - val_dense_9_loss: 0.0147 - val_dense_14_loss: 0.0147\n",
            "Epoch 423/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0297 - dense_9_loss: 0.0149 - dense_14_loss: 0.0149 - val_loss: 0.0303 - val_dense_9_loss: 0.0154 - val_dense_14_loss: 0.0148\n",
            "Epoch 424/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0313 - dense_9_loss: 0.0154 - dense_14_loss: 0.0159 - val_loss: 0.0286 - val_dense_9_loss: 0.0144 - val_dense_14_loss: 0.0142\n",
            "Epoch 425/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0299 - dense_9_loss: 0.0147 - dense_14_loss: 0.0152 - val_loss: 0.0293 - val_dense_9_loss: 0.0144 - val_dense_14_loss: 0.0149\n",
            "Epoch 426/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0301 - dense_9_loss: 0.0150 - dense_14_loss: 0.0151 - val_loss: 0.0338 - val_dense_9_loss: 0.0167 - val_dense_14_loss: 0.0171\n",
            "Epoch 427/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0301 - dense_9_loss: 0.0149 - dense_14_loss: 0.0152 - val_loss: 0.0285 - val_dense_9_loss: 0.0142 - val_dense_14_loss: 0.0143\n",
            "Epoch 428/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0306 - dense_9_loss: 0.0149 - dense_14_loss: 0.0156 - val_loss: 0.0281 - val_dense_9_loss: 0.0142 - val_dense_14_loss: 0.0139\n",
            "Epoch 429/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0300 - dense_9_loss: 0.0147 - dense_14_loss: 0.0152 - val_loss: 0.0285 - val_dense_9_loss: 0.0146 - val_dense_14_loss: 0.0139\n",
            "Epoch 430/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0284 - dense_9_loss: 0.0141 - dense_14_loss: 0.0144 - val_loss: 0.0298 - val_dense_9_loss: 0.0152 - val_dense_14_loss: 0.0146\n",
            "Epoch 431/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0300 - dense_9_loss: 0.0148 - dense_14_loss: 0.0152 - val_loss: 0.0282 - val_dense_9_loss: 0.0138 - val_dense_14_loss: 0.0144\n",
            "Epoch 432/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0291 - dense_9_loss: 0.0145 - dense_14_loss: 0.0146 - val_loss: 0.0281 - val_dense_9_loss: 0.0139 - val_dense_14_loss: 0.0143\n",
            "Epoch 433/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0283 - dense_9_loss: 0.0140 - dense_14_loss: 0.0142 - val_loss: 0.0294 - val_dense_9_loss: 0.0146 - val_dense_14_loss: 0.0147\n",
            "Epoch 434/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0290 - dense_9_loss: 0.0143 - dense_14_loss: 0.0147 - val_loss: 0.0354 - val_dense_9_loss: 0.0183 - val_dense_14_loss: 0.0171\n",
            "Epoch 435/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0289 - dense_9_loss: 0.0143 - dense_14_loss: 0.0146 - val_loss: 0.0272 - val_dense_9_loss: 0.0136 - val_dense_14_loss: 0.0136\n",
            "Epoch 436/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0281 - dense_9_loss: 0.0137 - dense_14_loss: 0.0144 - val_loss: 0.0279 - val_dense_9_loss: 0.0140 - val_dense_14_loss: 0.0139\n",
            "Epoch 437/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0287 - dense_9_loss: 0.0141 - dense_14_loss: 0.0146 - val_loss: 0.0270 - val_dense_9_loss: 0.0135 - val_dense_14_loss: 0.0135\n",
            "Epoch 438/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0293 - dense_9_loss: 0.0144 - dense_14_loss: 0.0149 - val_loss: 0.0276 - val_dense_9_loss: 0.0138 - val_dense_14_loss: 0.0137\n",
            "Epoch 439/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0275 - dense_9_loss: 0.0136 - dense_14_loss: 0.0139 - val_loss: 0.0269 - val_dense_9_loss: 0.0133 - val_dense_14_loss: 0.0135\n",
            "Epoch 440/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0280 - dense_9_loss: 0.0137 - dense_14_loss: 0.0143 - val_loss: 0.0294 - val_dense_9_loss: 0.0145 - val_dense_14_loss: 0.0149\n",
            "Epoch 441/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0280 - dense_9_loss: 0.0137 - dense_14_loss: 0.0143 - val_loss: 0.0278 - val_dense_9_loss: 0.0146 - val_dense_14_loss: 0.0132\n",
            "Epoch 442/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0287 - dense_9_loss: 0.0143 - dense_14_loss: 0.0144 - val_loss: 0.0272 - val_dense_9_loss: 0.0136 - val_dense_14_loss: 0.0136\n",
            "Epoch 443/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0276 - dense_9_loss: 0.0137 - dense_14_loss: 0.0139 - val_loss: 0.0272 - val_dense_9_loss: 0.0138 - val_dense_14_loss: 0.0134\n",
            "Epoch 444/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0291 - dense_9_loss: 0.0147 - dense_14_loss: 0.0144 - val_loss: 0.0273 - val_dense_9_loss: 0.0133 - val_dense_14_loss: 0.0140\n",
            "Epoch 445/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0295 - dense_9_loss: 0.0149 - dense_14_loss: 0.0146 - val_loss: 0.0277 - val_dense_9_loss: 0.0133 - val_dense_14_loss: 0.0144\n",
            "Epoch 446/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0278 - dense_9_loss: 0.0137 - dense_14_loss: 0.0141 - val_loss: 0.0271 - val_dense_9_loss: 0.0133 - val_dense_14_loss: 0.0138\n",
            "Epoch 447/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0273 - dense_9_loss: 0.0135 - dense_14_loss: 0.0138 - val_loss: 0.0270 - val_dense_9_loss: 0.0135 - val_dense_14_loss: 0.0135\n",
            "Epoch 448/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0274 - dense_9_loss: 0.0136 - dense_14_loss: 0.0138 - val_loss: 0.0263 - val_dense_9_loss: 0.0131 - val_dense_14_loss: 0.0132\n",
            "Epoch 449/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0285 - dense_9_loss: 0.0140 - dense_14_loss: 0.0145 - val_loss: 0.0274 - val_dense_9_loss: 0.0138 - val_dense_14_loss: 0.0136\n",
            "Epoch 450/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0280 - dense_9_loss: 0.0137 - dense_14_loss: 0.0143 - val_loss: 0.0262 - val_dense_9_loss: 0.0129 - val_dense_14_loss: 0.0133\n",
            "Epoch 451/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0272 - dense_9_loss: 0.0134 - dense_14_loss: 0.0138 - val_loss: 0.0266 - val_dense_9_loss: 0.0132 - val_dense_14_loss: 0.0134\n",
            "Epoch 452/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0263 - dense_9_loss: 0.0129 - dense_14_loss: 0.0134 - val_loss: 0.0297 - val_dense_9_loss: 0.0144 - val_dense_14_loss: 0.0154\n",
            "Epoch 453/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0271 - dense_9_loss: 0.0135 - dense_14_loss: 0.0136 - val_loss: 0.0274 - val_dense_9_loss: 0.0135 - val_dense_14_loss: 0.0139\n",
            "Epoch 454/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0264 - dense_9_loss: 0.0131 - dense_14_loss: 0.0133 - val_loss: 0.0258 - val_dense_9_loss: 0.0129 - val_dense_14_loss: 0.0129\n",
            "Epoch 455/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0266 - dense_9_loss: 0.0132 - dense_14_loss: 0.0134 - val_loss: 0.0280 - val_dense_9_loss: 0.0138 - val_dense_14_loss: 0.0142\n",
            "Epoch 456/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0265 - dense_9_loss: 0.0131 - dense_14_loss: 0.0134 - val_loss: 0.0272 - val_dense_9_loss: 0.0138 - val_dense_14_loss: 0.0134\n",
            "Epoch 457/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0285 - dense_9_loss: 0.0140 - dense_14_loss: 0.0145 - val_loss: 0.0257 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0129\n",
            "Epoch 458/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0268 - dense_9_loss: 0.0132 - dense_14_loss: 0.0136 - val_loss: 0.0285 - val_dense_9_loss: 0.0151 - val_dense_14_loss: 0.0134\n",
            "Epoch 459/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0271 - dense_9_loss: 0.0135 - dense_14_loss: 0.0135 - val_loss: 0.0255 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0128\n",
            "Epoch 460/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0283 - dense_9_loss: 0.0140 - dense_14_loss: 0.0143 - val_loss: 0.0263 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0134\n",
            "Epoch 461/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0267 - dense_9_loss: 0.0131 - dense_14_loss: 0.0136 - val_loss: 0.0262 - val_dense_9_loss: 0.0130 - val_dense_14_loss: 0.0132\n",
            "Epoch 462/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0285 - dense_9_loss: 0.0139 - dense_14_loss: 0.0146 - val_loss: 0.0260 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0131\n",
            "Epoch 463/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0271 - dense_9_loss: 0.0134 - dense_14_loss: 0.0137 - val_loss: 0.0266 - val_dense_9_loss: 0.0130 - val_dense_14_loss: 0.0136\n",
            "Epoch 464/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0275 - dense_9_loss: 0.0136 - dense_14_loss: 0.0140 - val_loss: 0.0258 - val_dense_9_loss: 0.0127 - val_dense_14_loss: 0.0131\n",
            "Epoch 465/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0273 - dense_9_loss: 0.0135 - dense_14_loss: 0.0137 - val_loss: 0.0254 - val_dense_9_loss: 0.0127 - val_dense_14_loss: 0.0128\n",
            "Epoch 466/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0261 - dense_9_loss: 0.0128 - dense_14_loss: 0.0133 - val_loss: 0.0259 - val_dense_9_loss: 0.0129 - val_dense_14_loss: 0.0130\n",
            "Epoch 467/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0266 - dense_9_loss: 0.0130 - dense_14_loss: 0.0136 - val_loss: 0.0254 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0128\n",
            "Epoch 468/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0259 - dense_9_loss: 0.0127 - dense_14_loss: 0.0132 - val_loss: 0.0261 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0133\n",
            "Epoch 469/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0259 - dense_9_loss: 0.0126 - dense_14_loss: 0.0133 - val_loss: 0.0263 - val_dense_9_loss: 0.0127 - val_dense_14_loss: 0.0136\n",
            "Epoch 470/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0262 - dense_9_loss: 0.0129 - dense_14_loss: 0.0133 - val_loss: 0.0256 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0128\n",
            "Epoch 471/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0258 - dense_9_loss: 0.0127 - dense_14_loss: 0.0131 - val_loss: 0.0254 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0128\n",
            "Epoch 472/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0276 - dense_9_loss: 0.0138 - dense_14_loss: 0.0139 - val_loss: 0.0259 - val_dense_9_loss: 0.0127 - val_dense_14_loss: 0.0132\n",
            "Epoch 473/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0267 - dense_9_loss: 0.0132 - dense_14_loss: 0.0135 - val_loss: 0.0258 - val_dense_9_loss: 0.0131 - val_dense_14_loss: 0.0126\n",
            "Epoch 474/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0269 - dense_9_loss: 0.0134 - dense_14_loss: 0.0134 - val_loss: 0.0250 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0125\n",
            "Epoch 475/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0260 - dense_9_loss: 0.0129 - dense_14_loss: 0.0131 - val_loss: 0.0255 - val_dense_9_loss: 0.0125 - val_dense_14_loss: 0.0130\n",
            "Epoch 476/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0268 - dense_9_loss: 0.0132 - dense_14_loss: 0.0136 - val_loss: 0.0263 - val_dense_9_loss: 0.0125 - val_dense_14_loss: 0.0137\n",
            "Epoch 477/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0268 - dense_9_loss: 0.0132 - dense_14_loss: 0.0136 - val_loss: 0.0303 - val_dense_9_loss: 0.0156 - val_dense_14_loss: 0.0147\n",
            "Epoch 478/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0261 - dense_9_loss: 0.0129 - dense_14_loss: 0.0132 - val_loss: 0.0252 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0127\n",
            "Epoch 479/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0260 - dense_9_loss: 0.0128 - dense_14_loss: 0.0131 - val_loss: 0.0258 - val_dense_9_loss: 0.0132 - val_dense_14_loss: 0.0126\n",
            "Epoch 480/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0270 - dense_9_loss: 0.0135 - dense_14_loss: 0.0135 - val_loss: 0.0252 - val_dense_9_loss: 0.0125 - val_dense_14_loss: 0.0127\n",
            "Epoch 481/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0264 - dense_9_loss: 0.0128 - dense_14_loss: 0.0136 - val_loss: 0.0251 - val_dense_9_loss: 0.0125 - val_dense_14_loss: 0.0125\n",
            "Epoch 482/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0260 - dense_9_loss: 0.0128 - dense_14_loss: 0.0133 - val_loss: 0.0248 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0124\n",
            "Epoch 483/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0259 - dense_9_loss: 0.0128 - dense_14_loss: 0.0131 - val_loss: 0.0254 - val_dense_9_loss: 0.0129 - val_dense_14_loss: 0.0125\n",
            "Epoch 484/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0278 - dense_9_loss: 0.0138 - dense_14_loss: 0.0139 - val_loss: 0.0323 - val_dense_9_loss: 0.0171 - val_dense_14_loss: 0.0152\n",
            "Epoch 485/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0266 - dense_9_loss: 0.0131 - dense_14_loss: 0.0135 - val_loss: 0.0250 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0127\n",
            "Epoch 486/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0273 - dense_9_loss: 0.0134 - dense_14_loss: 0.0139 - val_loss: 0.0252 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0126\n",
            "Epoch 487/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0258 - dense_9_loss: 0.0127 - dense_14_loss: 0.0131 - val_loss: 0.0264 - val_dense_9_loss: 0.0133 - val_dense_14_loss: 0.0131\n",
            "Epoch 488/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0264 - dense_9_loss: 0.0130 - dense_14_loss: 0.0134 - val_loss: 0.0253 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0128\n",
            "Epoch 489/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0265 - dense_9_loss: 0.0128 - dense_14_loss: 0.0137 - val_loss: 0.0265 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0138\n",
            "Epoch 490/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0263 - dense_9_loss: 0.0128 - dense_14_loss: 0.0134 - val_loss: 0.0259 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0135\n",
            "Epoch 491/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0273 - dense_9_loss: 0.0135 - dense_14_loss: 0.0138 - val_loss: 0.0247 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0124\n",
            "Epoch 492/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0255 - dense_9_loss: 0.0125 - dense_14_loss: 0.0129 - val_loss: 0.0251 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0126\n",
            "Epoch 493/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0268 - dense_9_loss: 0.0129 - dense_14_loss: 0.0140 - val_loss: 0.0263 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0140\n",
            "Epoch 494/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0257 - dense_9_loss: 0.0128 - dense_14_loss: 0.0129 - val_loss: 0.0247 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0125\n",
            "Epoch 495/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0259 - dense_9_loss: 0.0126 - dense_14_loss: 0.0133 - val_loss: 0.0253 - val_dense_9_loss: 0.0123 - val_dense_14_loss: 0.0130\n",
            "Epoch 496/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0251 - dense_9_loss: 0.0123 - dense_14_loss: 0.0128 - val_loss: 0.0260 - val_dense_9_loss: 0.0130 - val_dense_14_loss: 0.0130\n",
            "Epoch 497/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0262 - dense_9_loss: 0.0130 - dense_14_loss: 0.0132 - val_loss: 0.0262 - val_dense_9_loss: 0.0131 - val_dense_14_loss: 0.0131\n",
            "Epoch 498/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0276 - dense_9_loss: 0.0137 - dense_14_loss: 0.0139 - val_loss: 0.0245 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0123\n",
            "Epoch 499/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0261 - dense_9_loss: 0.0128 - dense_14_loss: 0.0133 - val_loss: 0.0248 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0126\n",
            "Epoch 500/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0256 - dense_9_loss: 0.0127 - dense_14_loss: 0.0129 - val_loss: 0.0247 - val_dense_9_loss: 0.0123 - val_dense_14_loss: 0.0125\n",
            "Epoch 501/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0251 - dense_9_loss: 0.0124 - dense_14_loss: 0.0127 - val_loss: 0.0247 - val_dense_9_loss: 0.0123 - val_dense_14_loss: 0.0124\n",
            "Epoch 502/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0251 - dense_9_loss: 0.0123 - dense_14_loss: 0.0128 - val_loss: 0.0292 - val_dense_9_loss: 0.0149 - val_dense_14_loss: 0.0143\n",
            "Epoch 503/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0256 - dense_9_loss: 0.0125 - dense_14_loss: 0.0130 - val_loss: 0.0245 - val_dense_9_loss: 0.0121 - val_dense_14_loss: 0.0124\n",
            "Epoch 504/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0254 - dense_9_loss: 0.0124 - dense_14_loss: 0.0129 - val_loss: 0.0255 - val_dense_9_loss: 0.0129 - val_dense_14_loss: 0.0126\n",
            "Epoch 505/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0249 - dense_9_loss: 0.0123 - dense_14_loss: 0.0126 - val_loss: 0.0259 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0133\n",
            "Epoch 506/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0259 - dense_9_loss: 0.0126 - dense_14_loss: 0.0133 - val_loss: 0.0293 - val_dense_9_loss: 0.0145 - val_dense_14_loss: 0.0148\n",
            "Epoch 507/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0264 - dense_9_loss: 0.0128 - dense_14_loss: 0.0136 - val_loss: 0.0269 - val_dense_9_loss: 0.0139 - val_dense_14_loss: 0.0129\n",
            "Epoch 508/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0264 - dense_9_loss: 0.0133 - dense_14_loss: 0.0131 - val_loss: 0.0253 - val_dense_9_loss: 0.0130 - val_dense_14_loss: 0.0124\n",
            "Epoch 509/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0257 - dense_9_loss: 0.0128 - dense_14_loss: 0.0129 - val_loss: 0.0254 - val_dense_9_loss: 0.0125 - val_dense_14_loss: 0.0130\n",
            "Epoch 510/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0266 - dense_9_loss: 0.0130 - dense_14_loss: 0.0136 - val_loss: 0.0243 - val_dense_9_loss: 0.0121 - val_dense_14_loss: 0.0123\n",
            "Epoch 511/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0249 - dense_9_loss: 0.0122 - dense_14_loss: 0.0127 - val_loss: 0.0245 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0122\n",
            "Epoch 512/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0253 - dense_9_loss: 0.0124 - dense_14_loss: 0.0129 - val_loss: 0.0257 - val_dense_9_loss: 0.0125 - val_dense_14_loss: 0.0132\n",
            "Epoch 513/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0254 - dense_9_loss: 0.0124 - dense_14_loss: 0.0129 - val_loss: 0.0242 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0121\n",
            "Epoch 514/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0250 - dense_9_loss: 0.0123 - dense_14_loss: 0.0127 - val_loss: 0.0254 - val_dense_9_loss: 0.0123 - val_dense_14_loss: 0.0131\n",
            "Epoch 515/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0254 - dense_9_loss: 0.0124 - dense_14_loss: 0.0130 - val_loss: 0.0273 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0147\n",
            "Epoch 516/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0253 - dense_9_loss: 0.0124 - dense_14_loss: 0.0129 - val_loss: 0.0242 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0122\n",
            "Epoch 517/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0260 - dense_9_loss: 0.0127 - dense_14_loss: 0.0133 - val_loss: 0.0251 - val_dense_9_loss: 0.0129 - val_dense_14_loss: 0.0123\n",
            "Epoch 518/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0254 - dense_9_loss: 0.0127 - dense_14_loss: 0.0127 - val_loss: 0.0251 - val_dense_9_loss: 0.0125 - val_dense_14_loss: 0.0125\n",
            "Epoch 519/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0256 - dense_9_loss: 0.0126 - dense_14_loss: 0.0130 - val_loss: 0.0270 - val_dense_9_loss: 0.0136 - val_dense_14_loss: 0.0134\n",
            "Epoch 520/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0251 - dense_9_loss: 0.0124 - dense_14_loss: 0.0127 - val_loss: 0.0245 - val_dense_9_loss: 0.0121 - val_dense_14_loss: 0.0124\n",
            "Epoch 521/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0248 - dense_9_loss: 0.0123 - dense_14_loss: 0.0126 - val_loss: 0.0253 - val_dense_9_loss: 0.0127 - val_dense_14_loss: 0.0126\n",
            "Epoch 522/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0261 - dense_9_loss: 0.0132 - dense_14_loss: 0.0129 - val_loss: 0.0264 - val_dense_9_loss: 0.0137 - val_dense_14_loss: 0.0127\n",
            "Epoch 523/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0263 - dense_9_loss: 0.0130 - dense_14_loss: 0.0133 - val_loss: 0.0267 - val_dense_9_loss: 0.0134 - val_dense_14_loss: 0.0133\n",
            "Epoch 524/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0246 - dense_9_loss: 0.0121 - dense_14_loss: 0.0125 - val_loss: 0.0245 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0124\n",
            "Epoch 525/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0248 - dense_9_loss: 0.0123 - dense_14_loss: 0.0125 - val_loss: 0.0241 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0121\n",
            "Epoch 526/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0259 - dense_9_loss: 0.0127 - dense_14_loss: 0.0132 - val_loss: 0.0283 - val_dense_9_loss: 0.0131 - val_dense_14_loss: 0.0151\n",
            "Epoch 527/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0265 - dense_9_loss: 0.0127 - dense_14_loss: 0.0137 - val_loss: 0.0246 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0124\n",
            "Epoch 528/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0246 - dense_9_loss: 0.0121 - dense_14_loss: 0.0126 - val_loss: 0.0240 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0120\n",
            "Epoch 529/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0252 - dense_9_loss: 0.0125 - dense_14_loss: 0.0127 - val_loss: 0.0252 - val_dense_9_loss: 0.0127 - val_dense_14_loss: 0.0125\n",
            "Epoch 530/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0250 - dense_9_loss: 0.0121 - dense_14_loss: 0.0129 - val_loss: 0.0244 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0122\n",
            "Epoch 531/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0254 - dense_9_loss: 0.0126 - dense_14_loss: 0.0128 - val_loss: 0.0245 - val_dense_9_loss: 0.0123 - val_dense_14_loss: 0.0123\n",
            "Epoch 532/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0260 - dense_9_loss: 0.0127 - dense_14_loss: 0.0133 - val_loss: 0.0271 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0144\n",
            "Epoch 533/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0257 - dense_9_loss: 0.0125 - dense_14_loss: 0.0132 - val_loss: 0.0247 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0126\n",
            "Epoch 534/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0259 - dense_9_loss: 0.0125 - dense_14_loss: 0.0134 - val_loss: 0.0308 - val_dense_9_loss: 0.0133 - val_dense_14_loss: 0.0175\n",
            "Epoch 535/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0260 - dense_9_loss: 0.0126 - dense_14_loss: 0.0134 - val_loss: 0.0244 - val_dense_9_loss: 0.0119 - val_dense_14_loss: 0.0125\n",
            "Epoch 536/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0261 - dense_9_loss: 0.0125 - dense_14_loss: 0.0135 - val_loss: 0.0248 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0128\n",
            "Epoch 537/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0242 - dense_9_loss: 0.0119 - dense_14_loss: 0.0123 - val_loss: 0.0248 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0124\n",
            "Epoch 538/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0252 - dense_9_loss: 0.0123 - dense_14_loss: 0.0129 - val_loss: 0.0241 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0122\n",
            "Epoch 539/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0254 - dense_9_loss: 0.0126 - dense_14_loss: 0.0128 - val_loss: 0.0242 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0120\n",
            "Epoch 540/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0246 - dense_9_loss: 0.0122 - dense_14_loss: 0.0124 - val_loss: 0.0240 - val_dense_9_loss: 0.0119 - val_dense_14_loss: 0.0120\n",
            "Epoch 541/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0250 - dense_9_loss: 0.0123 - dense_14_loss: 0.0127 - val_loss: 0.0260 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0138\n",
            "Epoch 542/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0248 - dense_9_loss: 0.0122 - dense_14_loss: 0.0126 - val_loss: 0.0266 - val_dense_9_loss: 0.0134 - val_dense_14_loss: 0.0131\n",
            "Epoch 543/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0253 - dense_9_loss: 0.0125 - dense_14_loss: 0.0129 - val_loss: 0.0237 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0120\n",
            "Epoch 544/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0249 - dense_9_loss: 0.0124 - dense_14_loss: 0.0125 - val_loss: 0.0256 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0134\n",
            "Epoch 545/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0245 - dense_9_loss: 0.0121 - dense_14_loss: 0.0124 - val_loss: 0.0238 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0120\n",
            "Epoch 546/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0245 - dense_9_loss: 0.0120 - dense_14_loss: 0.0124 - val_loss: 0.0273 - val_dense_9_loss: 0.0142 - val_dense_14_loss: 0.0131\n",
            "Epoch 547/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0267 - dense_9_loss: 0.0133 - dense_14_loss: 0.0135 - val_loss: 0.0257 - val_dense_9_loss: 0.0135 - val_dense_14_loss: 0.0122\n",
            "Epoch 548/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0256 - dense_9_loss: 0.0131 - dense_14_loss: 0.0126 - val_loss: 0.0267 - val_dense_9_loss: 0.0130 - val_dense_14_loss: 0.0136\n",
            "Epoch 549/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0119 - dense_14_loss: 0.0123 - val_loss: 0.0242 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0121\n",
            "Epoch 550/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0245 - dense_9_loss: 0.0118 - dense_14_loss: 0.0126 - val_loss: 0.0249 - val_dense_9_loss: 0.0119 - val_dense_14_loss: 0.0130\n",
            "Epoch 551/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0267 - dense_9_loss: 0.0135 - dense_14_loss: 0.0131 - val_loss: 0.0275 - val_dense_9_loss: 0.0141 - val_dense_14_loss: 0.0134\n",
            "Epoch 552/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0249 - dense_9_loss: 0.0123 - dense_14_loss: 0.0126 - val_loss: 0.0281 - val_dense_9_loss: 0.0142 - val_dense_14_loss: 0.0139\n",
            "Epoch 553/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0119 - dense_14_loss: 0.0122 - val_loss: 0.0263 - val_dense_9_loss: 0.0133 - val_dense_14_loss: 0.0130\n",
            "Epoch 554/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0242 - dense_9_loss: 0.0120 - dense_14_loss: 0.0122 - val_loss: 0.0260 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0136\n",
            "Epoch 555/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0244 - dense_9_loss: 0.0120 - dense_14_loss: 0.0124 - val_loss: 0.0236 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0119\n",
            "Epoch 556/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0250 - dense_9_loss: 0.0123 - dense_14_loss: 0.0127 - val_loss: 0.0352 - val_dense_9_loss: 0.0178 - val_dense_14_loss: 0.0174\n",
            "Epoch 557/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0252 - dense_9_loss: 0.0125 - dense_14_loss: 0.0127 - val_loss: 0.0244 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0123\n",
            "Epoch 558/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0244 - dense_9_loss: 0.0120 - dense_14_loss: 0.0124 - val_loss: 0.0241 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0119\n",
            "Epoch 559/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0265 - dense_9_loss: 0.0134 - dense_14_loss: 0.0131 - val_loss: 0.0236 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0119\n",
            "Epoch 560/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0261 - dense_9_loss: 0.0129 - dense_14_loss: 0.0132 - val_loss: 0.0294 - val_dense_9_loss: 0.0143 - val_dense_14_loss: 0.0151\n",
            "Epoch 561/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0255 - dense_9_loss: 0.0127 - dense_14_loss: 0.0128 - val_loss: 0.0236 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0119\n",
            "Epoch 562/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0240 - dense_9_loss: 0.0119 - dense_14_loss: 0.0121 - val_loss: 0.0236 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0118\n",
            "Epoch 563/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0247 - dense_9_loss: 0.0120 - dense_14_loss: 0.0127 - val_loss: 0.0237 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0120\n",
            "Epoch 564/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0240 - dense_9_loss: 0.0117 - dense_14_loss: 0.0122 - val_loss: 0.0249 - val_dense_9_loss: 0.0121 - val_dense_14_loss: 0.0128\n",
            "Epoch 565/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0239 - dense_9_loss: 0.0116 - dense_14_loss: 0.0123 - val_loss: 0.0236 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0119\n",
            "Epoch 566/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0247 - dense_9_loss: 0.0122 - dense_14_loss: 0.0125 - val_loss: 0.0241 - val_dense_9_loss: 0.0119 - val_dense_14_loss: 0.0122\n",
            "Epoch 567/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0259 - dense_9_loss: 0.0127 - dense_14_loss: 0.0132 - val_loss: 0.0238 - val_dense_9_loss: 0.0119 - val_dense_14_loss: 0.0119\n",
            "Epoch 568/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0238 - dense_9_loss: 0.0117 - dense_14_loss: 0.0121 - val_loss: 0.0285 - val_dense_9_loss: 0.0139 - val_dense_14_loss: 0.0146\n",
            "Epoch 569/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0118 - dense_14_loss: 0.0122 - val_loss: 0.0233 - val_dense_9_loss: 0.0115 - val_dense_14_loss: 0.0118\n",
            "Epoch 570/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0239 - dense_9_loss: 0.0117 - dense_14_loss: 0.0122 - val_loss: 0.0244 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0126\n",
            "Epoch 571/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0239 - dense_9_loss: 0.0117 - dense_14_loss: 0.0121 - val_loss: 0.0268 - val_dense_9_loss: 0.0131 - val_dense_14_loss: 0.0136\n",
            "Epoch 572/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0119 - dense_14_loss: 0.0123 - val_loss: 0.0256 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0130\n",
            "Epoch 573/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0272 - dense_9_loss: 0.0135 - dense_14_loss: 0.0137 - val_loss: 0.0321 - val_dense_9_loss: 0.0168 - val_dense_14_loss: 0.0153\n",
            "Epoch 574/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0243 - dense_9_loss: 0.0119 - dense_14_loss: 0.0124 - val_loss: 0.0231 - val_dense_9_loss: 0.0115 - val_dense_14_loss: 0.0116\n",
            "Epoch 575/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0249 - dense_9_loss: 0.0122 - dense_14_loss: 0.0127 - val_loss: 0.0242 - val_dense_9_loss: 0.0119 - val_dense_14_loss: 0.0123\n",
            "Epoch 576/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0244 - dense_9_loss: 0.0121 - dense_14_loss: 0.0124 - val_loss: 0.0291 - val_dense_9_loss: 0.0147 - val_dense_14_loss: 0.0144\n",
            "Epoch 577/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0252 - dense_9_loss: 0.0124 - dense_14_loss: 0.0128 - val_loss: 0.0269 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0142\n",
            "Epoch 578/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0118 - dense_14_loss: 0.0123 - val_loss: 0.0248 - val_dense_9_loss: 0.0127 - val_dense_14_loss: 0.0122\n",
            "Epoch 579/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0236 - dense_9_loss: 0.0116 - dense_14_loss: 0.0120 - val_loss: 0.0241 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0122\n",
            "Epoch 580/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0247 - dense_9_loss: 0.0121 - dense_14_loss: 0.0125 - val_loss: 0.0263 - val_dense_9_loss: 0.0134 - val_dense_14_loss: 0.0129\n",
            "Epoch 581/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0240 - dense_9_loss: 0.0118 - dense_14_loss: 0.0122 - val_loss: 0.0251 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0127\n",
            "Epoch 582/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0241 - dense_9_loss: 0.0118 - dense_14_loss: 0.0123 - val_loss: 0.0239 - val_dense_9_loss: 0.0119 - val_dense_14_loss: 0.0121\n",
            "Epoch 583/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0240 - dense_9_loss: 0.0118 - dense_14_loss: 0.0122 - val_loss: 0.0246 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0128\n",
            "Epoch 584/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0252 - dense_9_loss: 0.0122 - dense_14_loss: 0.0129 - val_loss: 0.0281 - val_dense_9_loss: 0.0135 - val_dense_14_loss: 0.0147\n",
            "Epoch 585/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0118 - dense_14_loss: 0.0123 - val_loss: 0.0239 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0121\n",
            "Epoch 586/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0117 - dense_14_loss: 0.0124 - val_loss: 0.0235 - val_dense_9_loss: 0.0115 - val_dense_14_loss: 0.0120\n",
            "Epoch 587/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0238 - dense_9_loss: 0.0117 - dense_14_loss: 0.0121 - val_loss: 0.0258 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0130\n",
            "Epoch 588/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0248 - dense_9_loss: 0.0122 - dense_14_loss: 0.0126 - val_loss: 0.0256 - val_dense_9_loss: 0.0135 - val_dense_14_loss: 0.0121\n",
            "Epoch 589/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0245 - dense_9_loss: 0.0120 - dense_14_loss: 0.0125 - val_loss: 0.0235 - val_dense_9_loss: 0.0116 - val_dense_14_loss: 0.0120\n",
            "Epoch 590/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0251 - dense_9_loss: 0.0121 - dense_14_loss: 0.0130 - val_loss: 0.0235 - val_dense_9_loss: 0.0116 - val_dense_14_loss: 0.0119\n",
            "Epoch 591/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0269 - dense_9_loss: 0.0130 - dense_14_loss: 0.0139 - val_loss: 0.0239 - val_dense_9_loss: 0.0115 - val_dense_14_loss: 0.0124\n",
            "Epoch 592/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0245 - dense_9_loss: 0.0121 - dense_14_loss: 0.0125 - val_loss: 0.0234 - val_dense_9_loss: 0.0115 - val_dense_14_loss: 0.0119\n",
            "Epoch 593/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0243 - dense_9_loss: 0.0118 - dense_14_loss: 0.0125 - val_loss: 0.0269 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0147\n",
            "Epoch 594/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0234 - dense_9_loss: 0.0114 - dense_14_loss: 0.0119 - val_loss: 0.0232 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0115\n",
            "Epoch 595/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0122 - dense_14_loss: 0.0119 - val_loss: 0.0228 - val_dense_9_loss: 0.0113 - val_dense_14_loss: 0.0114\n",
            "Epoch 596/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0237 - dense_9_loss: 0.0118 - dense_14_loss: 0.0119 - val_loss: 0.0242 - val_dense_9_loss: 0.0119 - val_dense_14_loss: 0.0123\n",
            "Epoch 597/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0235 - dense_9_loss: 0.0115 - dense_14_loss: 0.0120 - val_loss: 0.0234 - val_dense_9_loss: 0.0115 - val_dense_14_loss: 0.0119\n",
            "Epoch 598/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0234 - dense_9_loss: 0.0114 - dense_14_loss: 0.0120 - val_loss: 0.0239 - val_dense_9_loss: 0.0120 - val_dense_14_loss: 0.0119\n",
            "Epoch 599/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0249 - dense_9_loss: 0.0123 - dense_14_loss: 0.0126 - val_loss: 0.0229 - val_dense_9_loss: 0.0113 - val_dense_14_loss: 0.0116\n",
            "Epoch 600/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0233 - dense_9_loss: 0.0115 - dense_14_loss: 0.0118 - val_loss: 0.0234 - val_dense_9_loss: 0.0113 - val_dense_14_loss: 0.0121\n",
            "Epoch 601/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0246 - dense_9_loss: 0.0121 - dense_14_loss: 0.0125 - val_loss: 0.0254 - val_dense_9_loss: 0.0134 - val_dense_14_loss: 0.0120\n",
            "Epoch 602/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0255 - dense_9_loss: 0.0123 - dense_14_loss: 0.0133 - val_loss: 0.0244 - val_dense_9_loss: 0.0116 - val_dense_14_loss: 0.0129\n",
            "Epoch 603/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0241 - dense_9_loss: 0.0118 - dense_14_loss: 0.0123 - val_loss: 0.0242 - val_dense_9_loss: 0.0115 - val_dense_14_loss: 0.0127\n",
            "Epoch 604/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0238 - dense_9_loss: 0.0120 - dense_14_loss: 0.0118 - val_loss: 0.0241 - val_dense_9_loss: 0.0122 - val_dense_14_loss: 0.0120\n",
            "Epoch 605/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0238 - dense_9_loss: 0.0117 - dense_14_loss: 0.0121 - val_loss: 0.0346 - val_dense_9_loss: 0.0169 - val_dense_14_loss: 0.0178\n",
            "Epoch 606/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0249 - dense_9_loss: 0.0124 - dense_14_loss: 0.0125 - val_loss: 0.0243 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0125\n",
            "Epoch 607/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0232 - dense_9_loss: 0.0114 - dense_14_loss: 0.0118 - val_loss: 0.0232 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0115\n",
            "Epoch 608/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0242 - dense_9_loss: 0.0120 - dense_14_loss: 0.0123 - val_loss: 0.0260 - val_dense_9_loss: 0.0132 - val_dense_14_loss: 0.0128\n",
            "Epoch 609/2000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0243 - dense_9_loss: 0.0121 - dense_14_loss: 0.0122 - val_loss: 0.0261 - val_dense_9_loss: 0.0127 - val_dense_14_loss: 0.0134\n",
            "Epoch 610/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0234 - dense_9_loss: 0.0116 - dense_14_loss: 0.0119 - val_loss: 0.0252 - val_dense_9_loss: 0.0126 - val_dense_14_loss: 0.0125\n",
            "Epoch 611/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0240 - dense_9_loss: 0.0119 - dense_14_loss: 0.0120 - val_loss: 0.0231 - val_dense_9_loss: 0.0113 - val_dense_14_loss: 0.0118\n",
            "Epoch 612/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0233 - dense_9_loss: 0.0113 - dense_14_loss: 0.0120 - val_loss: 0.0242 - val_dense_9_loss: 0.0121 - val_dense_14_loss: 0.0122\n",
            "Epoch 613/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0227 - dense_9_loss: 0.0112 - dense_14_loss: 0.0115 - val_loss: 0.0234 - val_dense_9_loss: 0.0118 - val_dense_14_loss: 0.0117\n",
            "Epoch 614/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0237 - dense_9_loss: 0.0116 - dense_14_loss: 0.0121 - val_loss: 0.0299 - val_dense_9_loss: 0.0151 - val_dense_14_loss: 0.0148\n",
            "Epoch 615/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0236 - dense_9_loss: 0.0116 - dense_14_loss: 0.0120 - val_loss: 0.0241 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0125\n",
            "Epoch 616/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0232 - dense_9_loss: 0.0114 - dense_14_loss: 0.0118 - val_loss: 0.0231 - val_dense_9_loss: 0.0112 - val_dense_14_loss: 0.0119\n",
            "Epoch 617/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0237 - dense_9_loss: 0.0117 - dense_14_loss: 0.0120 - val_loss: 0.0236 - val_dense_9_loss: 0.0117 - val_dense_14_loss: 0.0119\n",
            "Epoch 618/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0235 - dense_9_loss: 0.0116 - dense_14_loss: 0.0119 - val_loss: 0.0247 - val_dense_9_loss: 0.0124 - val_dense_14_loss: 0.0123\n",
            "Epoch 619/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0238 - dense_9_loss: 0.0115 - dense_14_loss: 0.0122 - val_loss: 0.0229 - val_dense_9_loss: 0.0113 - val_dense_14_loss: 0.0116\n",
            "Epoch 620/2000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.0230 - dense_9_loss: 0.0114 - dense_14_loss: 0.0117 - val_loss: 0.0257 - val_dense_9_loss: 0.0128 - val_dense_14_loss: 0.0129\n",
            "Epoch 00620: early stopping\n",
            "CPU times: user 3min 34s, sys: 27.6 s, total: 4min 2s\n",
            "Wall time: 3min 4s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ac1b35668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Bt1R29Qjzj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0bed72c2-a48c-427c-a179-289f0a1635dc"
      },
      "source": [
        "model_loss = pd.DataFrame(model_TN.history.history)\n",
        "model_loss.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0ac1ac4668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjpiipdgRtup",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d6d15120-9123-46fd-dd6e-6228f41da047"
      },
      "source": [
        "predictions = model_TN.predict(X_test)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None, 9) for input Tensor(\"input_1:0\", shape=(None, None, 9), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[15.85364 ],\n",
              "        [18.667889],\n",
              "        [10.154156],\n",
              "        ...,\n",
              "        [12.208869],\n",
              "        [13.35763 ],\n",
              "        [19.152866]], dtype=float32),\n",
              " array([[15.853533, 15.848686, 15.846228, ..., 15.847078, 15.853299,\n",
              "         15.850801],\n",
              "        [18.699324, 18.702284, 18.702812, ..., 18.701149, 18.700705,\n",
              "         18.701807],\n",
              "        [10.147136, 10.137468, 10.143947, ..., 10.132139, 10.142564,\n",
              "         10.136511],\n",
              "        ...,\n",
              "        [12.193449, 12.199344, 12.198813, ..., 12.198003, 12.196786,\n",
              "         12.198474],\n",
              "        [13.383968, 13.391096, 13.386312, ..., 13.394348, 13.387536,\n",
              "         13.394094],\n",
              "        [19.156517, 19.157717, 19.156803, ..., 19.156223, 19.157715,\n",
              "         19.15767 ]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IthISq6cR0a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1705e54b-d2ea-4011-f6e8-5190560a565a"
      },
      "source": [
        "np.sqrt(mean_squared_error(y_test,predictions[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11305163164997559"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVmUmV-_R4ax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c43cc1d-1299-481a-f36a-3a9714652d88"
      },
      "source": [
        "explained_variance_score(y_test,predictions[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9987473305979403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMnpZ8TIR-Gm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0ed59a74-30b7-4338-bec6-551abb4f6dd7"
      },
      "source": [
        "result_df = pd.DataFrame()\n",
        "result_df['True values'] = y_test\n",
        "result_df['Predictions'] = predictions[0]\n",
        "\n",
        "result_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True values</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.810335</td>\n",
              "      <td>15.853640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18.714896</td>\n",
              "      <td>18.667889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.997362</td>\n",
              "      <td>10.154156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.636960</td>\n",
              "      <td>17.593699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.433450</td>\n",
              "      <td>15.363018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>14.035750</td>\n",
              "      <td>13.856400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>12.230762</td>\n",
              "      <td>12.135015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>12.135982</td>\n",
              "      <td>12.208869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>13.395426</td>\n",
              "      <td>13.357630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>19.235523</td>\n",
              "      <td>19.152866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      True values  Predictions\n",
              "0       15.810335    15.853640\n",
              "1       18.714896    18.667889\n",
              "2        9.997362    10.154156\n",
              "3       17.636960    17.593699\n",
              "4       15.433450    15.363018\n",
              "...           ...          ...\n",
              "2995    14.035750    13.856400\n",
              "2996    12.230762    12.135015\n",
              "2997    12.135982    12.208869\n",
              "2998    13.395426    13.357630\n",
              "2999    19.235523    19.152866\n",
              "\n",
              "[3000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyfQUOpUSCMC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "22561e22-3409-44e7-f6d6-8e725ea27e40"
      },
      "source": [
        "sns.scatterplot(x = result_df['True values'], y = result_df['Predictions'], hue = \"Predictions\", data = result_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0ac0114ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV67cc6-6BNt"
      },
      "source": [
        "# DEVELOPING THE TERM STRUCTURE OF THE VOLATILITY SWAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t0RGeRsSFhS"
      },
      "source": [
        "def bs_vega(S,K,T,r,v,q=0.0):\n",
        "    d1 = (np.log(S/K)+(r+v*v/2.)*T)/(v*np.sqrt(T))\n",
        "    return S * np.sqrt(T)*si.norm.pdf(d1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_jCAm-7HgW"
      },
      "source": [
        "def find_vol(target_value, S, K, T, r):\n",
        "    MAX_ITERATIONS = 100\n",
        "    PRECISION = 1.0e-5\n",
        "\n",
        "    sigma = 0.5\n",
        "    for i in range(0, MAX_ITERATIONS):\n",
        "        if (K < S):\n",
        "          price = euro_vanilla_call(S,K,T,r,sigma)\n",
        "          vega = bs_vega(S, K, T, r, sigma)\n",
        "          diff = target_value - price  # our root\n",
        "          #print (i,sigma, diff)\n",
        "          if (abs(diff) < PRECISION):\n",
        "              return sigma, i\n",
        "          sigma = sigma + diff/vega # f(x) / f'(x)\n",
        "        elif (K > S):\n",
        "          price = euro_vanilla_put(S,K,T,r,sigma)\n",
        "          vega = bs_vega(S, K, T, r, sigma)\n",
        "          diff = target_value - price  # our root\n",
        "          #print (i,sigma, diff)\n",
        "          if (abs(diff) < PRECISION):\n",
        "              return sigma, i\n",
        "          sigma = sigma + diff/vega # f(x) / f'(x)\n",
        "\n",
        "    iteration = i\n",
        "    # value wasn't found, return best guess so far\n",
        "    return sigma, iteration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Z9id6q7-R7"
      },
      "source": [
        "def local_vol(S0,S,volvol, rho, sigma):\n",
        "    x = np.log(S/S0)\n",
        "    volvec = volvol * volvol * x * x;\n",
        "    volvec += 2.0 * volvol * rho * sigma * x;\n",
        "    volvec += sigma * sigma;\n",
        "    volvec = np.sqrt(volvec);\n",
        "    return volvec;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cL5gs9N9vTo"
      },
      "source": [
        "#region Monte Carlo\n",
        "\n",
        "np.random.seed(20000)\n",
        "\n",
        "# Parameters\n",
        "S0 = 1000.; T = 1.0; r = 0.0;\n",
        "sigma = 0.20;\n",
        "volvol = 0.50;\n",
        "rho = -0.750;\n",
        "rhoBar = np.sqrt(1.0-rho*rho);\n",
        "\n",
        "M = 20; dt = T / M; I = 15000\n",
        "# Simulating I paths with M time steps\n",
        "\n",
        "S = np.zeros((M + 1, I))\n",
        "Sbs = np.zeros((M + 1, I))\n",
        "Slv = np.zeros((M + 1, I))\n",
        "vol = np.zeros((M + 1, I))\n",
        "vollv= np.zeros((M + 1, I))\n",
        "Slv[0] = S0\n",
        "Sbs[0] = S0\n",
        "S[0] = S0\n",
        "vol[0] = sigma\n",
        "vollv[0] = sigma\n",
        "\n",
        "z = sobol_seq.i4_sobol_generate(2*M,I);\n",
        "\n",
        "for t in range(1, M + 1):\n",
        " z1 = z[:,t-1];\n",
        " z2 = z[:,M+t-1];\n",
        " x1 = norm.ppf(z1);\n",
        " x2 = norm.ppf(z2);\n",
        "\n",
        " vol[t] = vol[t - 1] * np.exp((- 0.5 * volvol ** 2) * dt + volvol * math.sqrt(dt) * (rho*x1+rhoBar*x2))\n",
        " S[t] = S[t - 1] * np.exp((r - 0.5 * vol[t-1] ** 2) * dt + vol[t-1] * math.sqrt(dt) * x1)\n",
        " Sbs[t] = Sbs[t - 1] * np.exp((r - 0.5 * sigma ** 2) * dt + sigma * math.sqrt(dt) * x1)\n",
        " Slv[t] = Slv[t - 1] * np.exp((r - 0.5 * vollv[t-1] ** 2) * dt + vollv[t-1] * math.sqrt(dt) * x1)\n",
        " vollv[t] =  local_vol(S0, Slv[t], volvol, rho, sigma)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4TCL2jmZ3Q5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "126b75f5-749c-45f6-9d12-71dd594ea71c"
      },
      "source": [
        "Slv[-1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF1U8CRJZsrX"
      },
      "source": [
        "\n",
        "# Calculating the Monte Carlo estimator\n",
        "Kmin =  math.exp(-2.0*sigma*math.sqrt(T))\n",
        "sigma_array = np.array([0.29,0.28,0.27,0.26,0.25,0.24,0.23,0.22,0.21])\n",
        "C0 = [];\n",
        "iv = [];\n",
        "calc = [];\n",
        "ivBS = [];\n",
        "ivLV = [];\n",
        "\n",
        "total_bs = 0\n",
        "total_lv = 0\n",
        "total_sv = 0\n",
        "\n",
        "for i in range(len(K_array)):\n",
        "      #calc.append(K_array[i])\n",
        "      clv = math.exp(-r * T) * np.sum( np.maximum(Slv[-1] - K_array[i], 0) - np.maximum(Sbs[-1] - K_array[i], 0) ) / I + euro_vanilla_call(S0,K_array[i],T,r,sigma_array[i])\n",
        "      cbs = math.exp(-r * T) * np.sum( np.maximum(Sbs[-1] - K_array[i], 0) ) / I\n",
        "      csv = math.exp(-r * T) * np.sum( np.maximum(S[-1] - K_array[i], 0) - np.maximum(Sbs[-1] - K_array[i], 0) ) / I + euro_vanilla_call(S0,K_array[i],T,r,sigma_array[i])\n",
        "      plv = math.exp(-r * T) * np.sum( np.maximum(K_array[i] - Slv[-1], 0) - np.maximum(K_array[i] - Sbs[-1], 0) ) / I + euro_vanilla_put(S0,K_array[i],T,r,sigma_array[i])\n",
        "      pbs = math.exp(-r * T) * np.sum( K_array[i] - np.maximum(Sbs[-1], 0) ) / I\n",
        "      psv = math.exp(-r * T) * np.sum( K_array[i] - np.maximum(S[-1], 0) - np.maximum(K_array[i] - Sbs[-1], 0) ) / I + euro_vanilla_put(S0,K_array[i],T,r,sigma_array[i])\n",
        "      if i==0:\n",
        "        delta_K = K_array[i+1] - K_array[i]\n",
        "        if K_array[i] < S_star:\n",
        "          total_bs += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( K_array[i] - np.maximum(Sbs[-1], 0) ) / I)\n",
        "          total_lv += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( np.maximum(K_array[i] - Slv[-1], 0) - np.maximum(K_array[i] - Sbs[-1], 0) ) / I + euro_vanilla_put(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          total_sv += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( K_array[i] - np.maximum(S[-1], 0) - np.maximum(K_array[i] - Sbs[-1], 0) ) / I + euro_vanilla_put(S0,K_array[i],T,r,sigma_array[i])) \n",
        "          break\n",
        "        elif K_array[i] > S_star:\n",
        "          total_bs += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( np.maximum(Sbs[-1] - K_array[i], 0) ) / I)\n",
        "          total_lv += ((delta_K/K_array**2)*math.exp(-r * T) * np.sum( np.maximum(Slv[-1] - K_array[i], 0) - np.maximum(Sbs[-1] - K_array[i], 0) ) / I + euro_vanilla_call(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          total_sv += ((delta_K/K_array**2)*math.exp(-r * T) * np.sum( np.maximum(S[-1] - K_array[i], 0) - np.maximum(Sbs[-1] - K_array[i], 0) ) / I + euro_vanilla_call(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          break\n",
        "        break\n",
        "\n",
        "      elif ((i>=1) and (i<=n-2)):\n",
        "        delta_K = 0.5*(K_array[i+1] - K_array[i-1])\n",
        "        if K_array[i] < S_star:\n",
        "          total_bs += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( K_array[i] - np.maximum(Sbs[-1], 0) ) / I)\n",
        "          total_lv += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( np.maximum(K_array[i] - Slv[-1], 0) - np.maximum(K_array[i] - Sbs[-1], 0) ) / I + euro_vanilla_put(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          total_sv += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( K_array[i] - np.maximum(S[-1], 0) - np.maximum(K_array[i] - Sbs[-1], 0) ) / I + euro_vanilla_put(S0,K_array[i],T,r,sigma_array[i])) \n",
        "          break\n",
        "        elif K_array[i] > S_star:\n",
        "          total_bs += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( np.maximum(Sbs[-1] - K_array[i], 0) ) / I)\n",
        "          total_lv += ((delta_K/K_array**2)*math.exp(-r * T) * np.sum( np.maximum(Slv[-1] - K_array[i], 0) - np.maximum(Sbs[-1] - K_array[i], 0) ) / I + euro_vanilla_call(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          total_sv += ((delta_K/K_array**2)*math.exp(-r * T) * np.sum( np.maximum(S[-1] - K_array[i], 0) - np.maximum(Sbs[-1] - K_array[i], 0) ) / I + euro_vanilla_call(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          break\n",
        "        break\n",
        "\n",
        "      else:\n",
        "        delta_K = K_array[i] - K_array[i-1]\n",
        "        if K_array[i] < S_star:\n",
        "          total_bs += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( K_array[i] - np.maximum(Sbs[-1], 0) ) / I)\n",
        "          total_lv += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( np.maximum(K_array[i] - Slv[-1], 0) - np.maximum(K_array[i] - Sbs[-1], 0) ) / I + euro_vanilla_put(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          total_sv += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( K_array[i] - np.maximum(S[-1], 0) - np.maximum(K_array[i] - Sbs[-1], 0) ) / I + euro_vanilla_put(S0,K_array[i],T,r,sigma_array[i])) \n",
        "          break\n",
        "        elif K_array[i] > S_star:\n",
        "          total_bs += ((delta_K/K_array**2)*np.exp(r*T)*math.exp(-r * T) * np.sum( np.maximum(Sbs[-1] - K_array[i], 0) ) / I)\n",
        "          total_lv += ((delta_K/K_array**2)*math.exp(-r * T) * np.sum( np.maximum(Slv[-1] - K_array[i], 0) - np.maximum(Sbs[-1] - K_array[i], 0) ) / I + euro_vanilla_call(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          total_sv += ((delta_K/K_array**2)*math.exp(-r * T) * np.sum( np.maximum(S[-1] - K_array[i], 0) - np.maximum(Sbs[-1] - K_array[i], 0) ) / I + euro_vanilla_call(S0,K_array[i],T,r,sigma_array[i]))\n",
        "          break\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXI6X-O9K0Mf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "931d0040-1edc-4f85-d733-b69dd9dc2e80"
      },
      "source": [
        "j_bs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.03213439, -0.0285675 , -0.02557841, -0.02304874, -0.02088896,\n",
              "       -0.0190303 , -0.01741929, -0.01601381, -0.01478033])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cn_Fq4UA93S"
      },
      "source": [
        "j_bs = ((2/T)*np.log(F0/S_star)) - ((2/T)*((F0/S_star)-1)) + ((2/T)*total_bs)\n",
        "j_lv = ((2/T)*np.log(F0/S_star)) - ((2/T)*((F0/S_star)-1)) + ((2/T)*total_bs)\n",
        "j_sv = ((2/T)*np.log(F0/S_star)) - ((2/T)*((F0/S_star)-1)) + ((2/T)*total_bs)\n",
        "var_bar = SD_avg_variance**2\n",
        "vol_price_bs = np.sqrt(j_bs) * (1 - ((1/8)*(var_bar/j_bs**2)))\n",
        "swap_price_bs = principal*((vol_price_bs - paid_vol)*np.exp(-r*T))\n",
        "vol_price_lv = np.sqrt(j_lv) * (1 - ((1/8)*(var_bar/j_lv**2)))\n",
        "swap_price_lv = principal*((vol_price_lv - paid_vol)*np.exp(-r*T))\n",
        "vol_price_sv = np.sqrt(j_sv) * (1 - ((1/8)*(var_bar/j_sv**2)))\n",
        "swap_price_sv = principal*((vol_price_sv - paid_vol)*np.exp(-r*T))\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBTYYa2SAtK6"
      },
      "source": [
        "iv.append(find_vol(swap_price_sv, S0,S_star,T,r))\n",
        "ivBS.append(find_vol(swap_price_bs, S0,S_star,T,r))\n",
        "ivLV.append(find_vol(swap_price_lv, S0,S_star,T,r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHcwvCUeE9bs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a7ae8cc3-dda1-49ed-94dc-e143c155d624"
      },
      "source": [
        "swap_price_bs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -28.1004235 ,  -31.4120858 ,  -35.49041231,  -40.60217361,\n",
              "        -47.12579719,  -55.61643689,  -66.91941151,  -82.37891265,\n",
              "       -104.24755153])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}